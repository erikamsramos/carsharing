[["index.html", "Online appendix for the paper: “Roundtrip, free-floating and peer-to-peer carsharing: A Bayesian behavioral analysis” Chapter 1 Foreword 1.1 Session info", " Online appendix for the paper: “Roundtrip, free-floating and peer-to-peer carsharing: A Bayesian behavioral analysis” Érika Martins Silva Ramos, David Issa Mattos and Cecilia Jakobsson Bergstad 2021-09-09 Chapter 1 Foreword This is the online appendix for the paper “Roundtrip, free-floating and peer-to-peer carsharing: A Bayesian behavioral analysis”. It contains a commented and reproducible code for all the analysis, tables and plots presented in the paper. The dataset is available in: http://doi.org/10.17632/wbf79hgn5c.1 1.1 Session info This appendix is compiled automatically and the following session information was used to generate this appendix: sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] knitr_1.33 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 ## [5] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.4 ## [9] ggplot2_3.3.5 tidyverse_1.3.1 bpcs_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.1 xfun_0.25 haven_2.3.1 colorspace_2.0-2 ## [5] vctrs_0.3.8 generics_0.1.0 htmltools_0.5.0 yaml_2.2.1 ## [9] utf8_1.2.2 rlang_0.4.11 jquerylib_0.1.4 pillar_1.6.2 ## [13] withr_2.4.2 glue_1.4.2 DBI_1.1.0 dbplyr_2.1.1 ## [17] modelr_0.1.8 readxl_1.3.1 lifecycle_1.0.0 munsell_0.5.0 ## [21] gtable_0.3.0 cellranger_1.1.0 rvest_1.0.1 evaluate_0.14 ## [25] fansi_0.5.0 broom_0.7.9 Rcpp_1.0.7 scales_1.1.1 ## [29] backports_1.2.1 jsonlite_1.7.2 fs_1.5.0 hms_1.1.0 ## [33] digest_0.6.27 stringi_1.7.4 bookdown_0.24 grid_4.0.3 ## [37] cli_3.0.1 tools_4.0.3 magrittr_2.0.1 crayon_1.4.1 ## [41] pkgconfig_2.0.3 ellipsis_0.3.2 xml2_1.3.2 reprex_2.0.1 ## [45] lubridate_1.7.10 assertthat_0.2.1 rmarkdown_2.10 httr_1.4.2 ## [49] rstudioapi_0.13 R6_2.5.1 compiler_4.0.3 "],["descriptive-statistics.html", "Chapter 2 Descriptive statistics 2.1 Importing and preparing the data 2.2 Descriptive statistics table 2.3 Tables for the paper", " Chapter 2 Descriptive statistics library(psych) library(haven) library(tidyverse) library(labelled) library(brms) library(Hmisc) library(table1) set.seed(3103) 2.1 Importing and preparing the data d &lt;- haven::read_sav(&quot;data/original/Users Germany.sav&quot;) Selecting only the variables of interest d1 &lt;- d %&gt;% select( first_operator=anbiet1, age = v29, gender = v28, income = v32, education = v30, frequency_modes = v08_10, #private car public_transport = v05, #transport public ticket frequency_modes_before_cs = v17_20, #private car n_cars_no_cs = v18, city = ort, n_cars = v03, children = v02_1, household_size = v01) Basic transformations Let’s convert everything to numeric (to get rid of the labels from SPSS). Then we recode the answers so we have more descriptive labels for the table. d2 &lt;- as.data.frame(sapply(d1, as.numeric)) #gender d2$gender&lt;-as.character(d2$gender) d2$gender &lt;- dplyr::recode(d2$gender, &#39;1&#39;=&#39;Male&#39;, &#39;2&#39;=&#39;Female&#39;, &#39;3&#39;=&#39;Other&#39;) d2$gender &lt;- as.factor(d2$gender) #age d2$age &lt;- 2019 - d2$age d2$age_c &lt;- scale(d2$age) #income d2$income &lt;- na_if(d2$income, 9) d2$income &lt;- as.character(d2$income) income_order &lt;-c(&#39;&lt; 1000&#39;, &#39;1000 to 2000&#39;, &#39;2000 to 3000&#39;, &#39;3000 to 4000&#39;, &#39;4000 to 5000&#39;, &#39;&gt; 5000&#39;) d2$income &lt;- dplyr::recode(d2$income, &#39;1&#39;=&#39;&lt; 1000&#39;, &#39;2&#39;=&#39;1000 to 2000&#39;, &#39;3&#39;=&#39;2000 to 3000&#39;, &#39;4&#39;=&#39;3000 to 4000&#39;, &#39;5&#39;=&#39;4000 to 5000&#39;, &#39;6&#39;=&#39;&gt; 5000&#39;) d2$income &lt;- factor(d2$income, levels = income_order, ordered = T) #first operator d2$first_operator &lt;- na_if(d2$first_operator, 9)#no information d2$first_operator &lt;- na_if(d2$first_operator, 10) #drivenow d2$first_operator &lt;- na_if(d2$first_operator, 11) #flinkster d2$first_operator &lt;- na_if(d2$first_operator, 99) #other d2$first_operator &lt;- as.character(d2$first_operator) d2$first_operator &lt;- dplyr::recode(d2$first_operator, &#39;1&#39;=&#39;COMB&#39;, #book n drive &#39;2&#39;=&#39;RTSB_B&#39;, #stadmobil, &#39;3&#39;=&#39;RTSB_A&#39;,#cambio &#39;4&#39;=&#39;RTSB_B&#39;, #stadmobil &#39;5&#39;=&#39;FF&#39;, #car2go &#39;6&#39;=&#39;P2P&#39; #drivy ) d2$first_operator &lt;- factor(d2$first_operator, ordered = FALSE) d2$first_operator &lt;- as.factor(d2$first_operator) #education d2$education &lt;- na_if(d2$education, 9) d2$education &lt;- as.character(d2$education) education_order &lt;-c(&#39;Secondary school 1&#39;, &#39;Secondary school 2&#39;, &#39;High school&#39;, &#39;University&#39;) d2$education &lt;- dplyr::recode(d2$education, &#39;1&#39;=&#39;Secondary school 1&#39;, &#39;2&#39;=&#39;Secondary school 2&#39;, &#39;3&#39;=&#39;High school&#39;, &#39;4&#39;=&#39;University&#39;) d2$education &lt;- factor(d2$education, levels = education_order, ordered = T) d2$public_transport &lt;- as.character(d2$public_transport) d2$public_transport &lt;- dplyr::recode(d2$public_transport, &#39;1&#39;=&#39;Yes&#39;, &#39;2&#39;=&#39;No&#39;) d2$city &lt;- as.character(d2$city) d2$city &lt;- dplyr::recode(d2$city, &#39;1&#39;=&#39;Frankfurt&#39;, &#39;2&#39;=&#39;Köln&#39;, &#39;3&#39;=&#39;Stuttgart&#39;, &#39;4&#39;=&#39;Others&#39;) d2$n_cars &lt;- as.character(d2$n_cars) d2$n_cars &lt;- dplyr::recode(d2$n_cars, &#39;1&#39;=&#39;One car&#39;, &#39;2&#39;=&#39;Two cars&#39;, &#39;3&#39;=&#39;Three or more cars&#39;, &#39;4&#39;=&#39;No car&#39;) n_car_order &lt;-c(&#39;No car&#39;, &#39;One car&#39;, &#39;Two cars&#39;, &#39;Three or more cars&#39;) d2$n_cars &lt;- factor(d2$n_cars, levels = n_car_order, ordered = T) d2$n_cars_no_cs &lt;- as.character(d2$n_cars_no_cs) d2$n_cars_no_cs &lt;- dplyr::recode(d2$n_cars_no_cs, &#39;1&#39;=&#39;One car&#39;, &#39;2&#39;=&#39;Two cars&#39;, &#39;3&#39;=&#39;Three or more cars&#39;, &#39;4&#39;=&#39;No car&#39;, &#39;5&#39;=&#39;Do not know&#39;) n_cars_no_cs_order &lt;-c(&#39;No car&#39;, &#39;One car&#39;, &#39;Two cars&#39;, &#39;Three or more cars&#39;, &#39;Do not know&#39;) d2$n_cars_no_cs &lt;- factor(d2$n_cars_no_cs, levels = n_cars_no_cs_order, ordered = T) d2$children &lt;- as.character(d2$children) d2$children &lt;- dplyr::recode(d2$children, &#39;0&#39;=&#39;Yes&#39;, &#39;1&#39;=&#39;No&#39;) d2$household_size &lt;- as.character(d2$household_size) d2$household_size &lt;- dplyr::recode(d2$household_size, &#39;1&#39;=&#39;1&#39;, &#39;2&#39;=&#39;2&#39;, &#39;3&#39;=&#39;3&#39;, &#39;4&#39;=&#39;4&#39;, &#39;5&#39;=&#39;&gt; 5&#39;) household_size_order &lt;-c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;&gt; 5&#39;) d2$household_size &lt;- factor(d2$household_size, levels = household_size_order, ordered = T) d2$frequency_modes &lt;- as.character(d2$frequency_modes) d2$frequency_modes &lt;- dplyr::recode(d2$frequency_modes, &#39;1&#39;=&#39;Daily&#39;, &#39;2&#39;=&#39;4-6 days a week&#39;, &#39;3&#39;=&#39;1-3 days a week&#39;, &#39;4&#39;=&#39;Do not know&#39;) frequency_modes_order &lt;-c(&#39;Daily&#39;,&#39;4-6 days a week&#39;,&#39;1-3 days a week&#39;,&#39;Do not know&#39;) d2$frequency_modes &lt;- factor(d2$frequency_modes, levels = frequency_modes_order, ordered = T) d2$frequency_modes_before_cs &lt;- as.character(d2$frequency_modes_before_cs) d2$frequency_modes_before_cs &lt;- dplyr::recode(d2$frequency_modes_before_cs, &#39;1&#39;=&#39;Less often than today&#39;, &#39;2&#39;=&#39;About as often as today&#39;, &#39;3&#39;=&#39;More often than today&#39;, &#39;4&#39;=&#39;Less frequently&#39;, &#39;5&#39;=&#39;Never&#39;) frequency_modes_before_cs_order &lt;-c(&#39;Daily&#39;,&#39;4-6 days a week&#39;,&#39;1-3 days a week&#39;,&#39;Less frequently&#39;,&#39;Never&#39;) d2$frequency_modes_before_cs &lt;- factor(d2$frequency_modes_before_cs, levels = frequency_modes_before_cs_order, ordered = T) 2.2 Descriptive statistics table Now let’s create a table of with the descriptive statistics. table1::label(d2$city) &lt;- &quot;City&quot; table1::label(d2$age) &lt;- &quot;Age&quot; table1::label(d2$gender) &lt;- &quot;Gender&quot; table1::label(d2$education) &lt;- &quot;Education&quot; table1::label(d2$income) &lt;- &quot;Household income before taxes (euro)&quot; table1::label(d2$household_size) &lt;- &quot;Household (number of persons cohabiting)&quot; table1::label(d2$children) &lt;- &quot;Presence of children in the household&quot; table1::label(d2$n_cars) &lt;- &quot;Current number of cars in the household with carsharing membership&quot; table1::label(d2$n_cars_no_cs) &lt;- &quot;Expected number of cars in the household without carsharing membership&quot; table1::label(d2$frequency_modes) &lt;- &quot;Frequency of use of private car&quot; table1::label(d2$public_transport) &lt;- &quot;Ownership of monthly PT ticket&quot; table1::label(d2$first_operator) &lt;- &quot;Main carsharing operator&quot; table1::table1(~ city+age+gender+education+income+household_size+children, data=d2,caption=&quot;Socio-demographic descriptive statistics of the sample&quot;) %&gt;% t1kable() Table 2.1: Socio-demographic descriptive statistics of the sample Overall (N=1121) City Frankfurt 465 (41.5%) Köln 136 (12.1%) Others 217 (19.4%) Stuttgart 303 (27.0%) Age Mean (SD) 46.5 (12.9) Median [Min, Max] 46.0 [20.0, 119] Missing 135 (12.0%) Gender Female 428 (38.2%) Male 551 (49.2%) Other 8 (0.7%) Missing 134 (12.0%) Education Secondary school 1 16 (1.4%) Secondary school 2 87 (7.8%) High school 164 (14.6%) University 710 (63.3%) Missing 144 (12.8%) Household income before taxes (euro) &lt; 1000 27 (2.4%) 1000 to 2000 127 (11.3%) 2000 to 3000 211 (18.8%) 3000 to 4000 163 (14.5%) 4000 to 5000 129 (11.5%) &gt; 5000 159 (14.2%) Missing 305 (27.2%) Household (number of persons cohabiting) 1 359 (32.0%) 2 440 (39.3%) 3 160 (14.3%) 4 133 (11.9%) &gt; 5 29 (2.6%) Presence of children in the household No 833 (74.3%) Yes 288 (25.7%) table1::table1(~ n_cars+n_cars_no_cs+frequency_modes+public_transport | first_operator, data=d2,caption=&quot;Descriptive statistics of private car use across carsharing business models&quot;) %&gt;% t1kable() Table 2.2: Descriptive statistics of private car use across carsharing business models COMB FF P2P RTSB_A RTSB_B Overall (N=226) (N=253) (N=214) (N=72) (N=316) (N=1121) Current number of cars in the household with carsharing membership No car 180 (79.6%) 107 (42.3%) 147 (68.7%) 55 (76.4%) 255 (80.7%) 763 (68.1%) One car 45 (19.9%) 104 (41.1%) 46 (21.5%) 15 (20.8%) 55 (17.4%) 279 (24.9%) Two cars 1 (0.4%) 30 (11.9%) 14 (6.5%) 1 (1.4%) 5 (1.6%) 56 (5.0%) Three or more cars 0 (0%) 12 (4.7%) 7 (3.3%) 1 (1.4%) 1 (0.3%) 23 (2.1%) Expected number of cars in the household without carsharing membership No car 69 (30.5%) 46 (18.2%) 71 (33.2%) 18 (25.0%) 124 (39.2%) 332 (29.6%) One car 106 (46.9%) 114 (45.1%) 84 (39.3%) 42 (58.3%) 124 (39.2%) 472 (42.1%) Two cars 10 (4.4%) 41 (16.2%) 20 (9.3%) 4 (5.6%) 16 (5.1%) 91 (8.1%) Three or more cars 0 (0%) 10 (4.0%) 5 (2.3%) 0 (0%) 0 (0%) 15 (1.3%) Do not know 34 (15.0%) 23 (9.1%) 19 (8.9%) 6 (8.3%) 40 (12.7%) 123 (11.0%) Missing 7 (3.1%) 19 (7.5%) 15 (7.0%) 2 (2.8%) 12 (3.8%) 88 (7.9%) Frequency of use of private car Daily 8 (3.5%) 29 (11.5%) 19 (8.9%) 2 (2.8%) 8 (2.5%) 72 (6.4%) 4-6 days a week 2 (0.9%) 33 (13.0%) 16 (7.5%) 3 (4.2%) 8 (2.5%) 68 (6.1%) 1-3 days a week 14 (6.2%) 63 (24.9%) 27 (12.6%) 5 (6.9%) 14 (4.4%) 129 (11.5%) Do not know 54 (23.9%) 55 (21.7%) 68 (31.8%) 20 (27.8%) 91 (28.8%) 298 (26.6%) Missing 148 (65.5%) 73 (28.9%) 84 (39.3%) 42 (58.3%) 195 (61.7%) 554 (49.4%) Ownership of monthly PT ticket No 97 (42.9%) 113 (44.7%) 103 (48.1%) 37 (51.4%) 97 (30.7%) 468 (41.7%) Yes 129 (57.1%) 140 (55.3%) 111 (51.9%) 35 (48.6%) 219 (69.3%) 653 (58.3%) 2.3 Tables for the paper table1::table1(~ city+age+gender+education+income+household_size+children, data=d2,caption=&quot;Socio-demographic descriptive statistics of the sample&quot;) %&gt;% t1kable(booktabs = T,format = &#39;latex&#39;, label=&#39;descriptive-socio&#39;) table1::table1(~ n_cars+n_cars_no_cs+frequency_modes+public_transport|first_operator, data=d2,caption=&quot;Descriptive statistics of private car use across carsharing business models&quot;) %&gt;% t1kable(booktabs = T,format = &#39;latex&#39;, label=&#39;descriptive-car&#39;) "],["motivators-for-using-a-carsharing-company.html", "Chapter 3 Motivators for using a carsharing company 3.1 Importing and preparing the data 3.2 Model 3.3 Figures for the paper", " Chapter 3 Motivators for using a carsharing company In this research question, we are assessing how each motivator is selected as important by the users. We control for age, gender and income as predictors and for the choice of the first operator as random effects library(psych) library(haven) library(tidyverse) library(labelled) library(brms) library(patchwork) set.seed(3103) 3.1 Importing and preparing the data d &lt;- haven::read_sav(&quot;data/original/Users Germany.sav&quot;) Selecting only the variables of interest d1 &lt;- d %&gt;% select( # DV first_operator=anbiet1, # IV accessibility=v39_10, expenses=v39_20, not_owning_a_car=v39_50, sustainability=v39_30, maintenance=v39_50, parking=v39_60, convenience = v39_70, #other control variables, age = v29, gender = v28, income = v32, education = v30) Basic transformations for correct fitting Let’s convert everything to numeric to get rid of the labels and process some of the other variables d2 &lt;- as.data.frame(sapply(d1, as.numeric)) #gender d2$gender &lt;- na_if(d2$gender, 3)#there are only 3 cases of other d2$gender&lt;-as.character(d2$gender) d2$gender &lt;- dplyr::recode(d2$gender, &#39;1&#39;=&#39;Male&#39;, &#39;2&#39;=&#39;Female&#39;, &#39;3&#39;=&#39;Other&#39;) d2$gender &lt;- as.factor(d2$gender) #age d2$age &lt;- 2019 - d2$age d2$age_c &lt;- scale(d2$age) #income d2$income &lt;- na_if(d2$income, 9) d2$income &lt;- as.character(d2$income) income_order &lt;-c(&#39;less_1000&#39;, &#39;1000_to_2000&#39;, &#39;2000_to_3000&#39;, &#39;3000_to_4000&#39;, &#39;4000_to_5000&#39;, &#39;greater_5000&#39;) d2$income &lt;- dplyr::recode(d2$income, &#39;1&#39;=&#39;less_1000&#39;, &#39;2&#39;=&#39;1000_to_2000&#39;, &#39;3&#39;=&#39;2000_to_3000&#39;, &#39;4&#39;=&#39;3000_to_4000&#39;, &#39;5&#39;=&#39;4000_to_5000&#39;, &#39;6&#39;=&#39;greater_5000&#39;) d2$income &lt;- factor(d2$income, levels = income_order, ordered = T) #first operator d2$first_operator &lt;- na_if(d2$first_operator, 9)#no information d2$first_operator &lt;- na_if(d2$first_operator, 10) #drivenow d2$first_operator &lt;- na_if(d2$first_operator, 11) #flinkster d2$first_operator &lt;- na_if(d2$first_operator, 99) #other d2$first_operator &lt;- as.character(d2$first_operator) d2$first_operator &lt;- dplyr::recode(d2$first_operator, &#39;1&#39;=&#39;COMB&#39;, #book n drive &#39;2&#39;=&#39;RTSB_B&#39;, #stadmobil, &#39;3&#39;=&#39;RTSB_A&#39;,#cambio &#39;4&#39;=&#39;RTSB_B&#39;, #stadmobil &#39;5&#39;=&#39;FF&#39;, #car2go &#39;6&#39;=&#39;P2P&#39; #drivy ) d2$first_operator &lt;- factor(d2$first_operator, ordered = FALSE) #education d2$education &lt;- na_if(d2$education, 9) d2$education &lt;- as.character(d2$education) education_order &lt;-c(&#39;SecondarySchool_1&#39;, &#39;SecondarySchool_2&#39;, &#39;Highschool&#39;, &#39;University&#39;) d2$education &lt;- dplyr::recode(d2$education, &#39;1&#39;=&#39;SecondarySchool_1&#39;, &#39;2&#39;=&#39;SecondarySchool_2&#39;, &#39;3&#39;=&#39;Highschool&#39;, &#39;4&#39;=&#39;University&#39;) d2$education &lt;- factor(d2$education, levels = education_order, ordered = T) d2$first_operator &lt;- as.factor(d2$first_operator) d2$accessibility &lt;- as.factor(d2$accessibility) d2$expenses&lt;- as.factor(d2$expenses) d2$not_owning_a_car&lt;- as.factor(d2$not_owning_a_car) d2$sustainability&lt;- as.factor(d2$sustainability) d2$maintenance&lt;- as.factor(d2$maintenance) d2$parking&lt;- as.factor(d2$parking) d2$convenience&lt;- as.factor(d2$convenience) d3 &lt;- drop_na(d2) 3.2 Model The model described here is a categorical model (multinomial model). 3.2.1 Priors for the models Now we are going to do the same analysis for each car sharing type company We are using the same weakly informative priors for all models. For the monotonic predictors we are using the default priors where the distance is the same between each item in the income and education scale We are also using the default priors for the random effects priors&lt;-c(set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;)) m_first_operator &lt;- brm(first_operator ~ accessibility + expenses +not_owning_a_car +sustainability+ maintenance + parking + convenience + gender + mo(income) + age_c + mo(education), data = d3, prior = priors, family = categorical(link = &quot;logit&quot;), cores=4 ) saveRDS(m_first_operator, &#39;models/m_first_operator.RDS&#39;) m_first_operator0 &lt;- brm(first_operator ~ gender + mo(income) + age_c + mo(education), data = d3, prior = priors, family = categorical(link = &quot;logit&quot;), cores=4 ) saveRDS(m_first_operator0, &#39;models/m_first_operator0.RDS&#39;) 3.2.2 Comparing the two models WAIC(m_first_operator) ## Warning: ## 3 (0.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. ## ## Computed from 4000 by 800 log-likelihood matrix ## ## Estimate SE ## elpd_waic -1108.1 20.2 ## p_waic 51.7 2.4 ## waic 2216.2 40.4 ## ## 3 (0.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. WAIC(m_first_operator0) ## Warning: ## 2 (0.2%) p_waic estimates greater than 0.4. We recommend trying loo instead. ## ## Computed from 4000 by 800 log-likelihood matrix ## ## Estimate SE ## elpd_waic -1148.6 16.2 ## p_waic 27.6 1.3 ## waic 2297.2 32.4 ## ## 2 (0.2%) p_waic estimates greater than 0.4. We recommend trying loo instead. 3.2.3 Summary summary(m_first_operator) ## Family: categorical ## Links: muFF = logit; muP2P = logit; muRTSBA = logit; muRTSBB = logit ## Formula: first_operator ~ accessibility + expenses + not_owning_a_car + sustainability + maintenance + parking + convenience + gender + mo(income) + age_c + mo(education) ## Data: d3 (Number of observations: 800) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## muFF_Intercept 1.46 0.76 0.05 3.05 1.00 2838 ## muP2P_Intercept 2.77 0.65 1.56 4.14 1.00 3184 ## muRTSBA_Intercept -3.94 1.41 -7.01 -1.35 1.00 3868 ## muRTSBB_Intercept 0.08 0.79 -1.57 1.56 1.00 2511 ## muFF_accessibility1 0.56 0.46 -0.33 1.45 1.00 3989 ## muFF_expenses1 -1.03 0.29 -1.62 -0.45 1.00 3936 ## muFF_not_owning_a_car1 -0.47 3.54 -7.49 6.28 1.00 4432 ## muFF_sustainability1 -0.52 0.26 -1.03 -0.02 1.00 4191 ## muFF_maintenance1 -0.28 3.54 -6.99 6.73 1.00 4399 ## muFF_parking1 0.03 0.26 -0.48 0.52 1.00 4442 ## muFF_convenience1 0.30 0.25 -0.17 0.79 1.00 4615 ## muFF_genderMale 0.66 0.24 0.18 1.13 1.00 3578 ## muFF_age_c -0.92 0.14 -1.20 -0.65 1.00 4147 ## muP2P_accessibility1 -0.41 0.41 -1.20 0.41 1.00 3518 ## muP2P_expenses1 -0.06 0.33 -0.71 0.58 1.00 4080 ## muP2P_not_owning_a_car1 -0.34 3.59 -7.45 6.71 1.00 4597 ## muP2P_sustainability1 -0.25 0.28 -0.81 0.29 1.00 4278 ## muP2P_maintenance1 -0.23 3.59 -7.30 6.90 1.00 4601 ## muP2P_parking1 -0.72 0.26 -1.23 -0.21 1.00 4490 ## muP2P_convenience1 0.10 0.27 -0.43 0.61 1.00 4464 ## muP2P_genderMale 0.83 0.25 0.35 1.33 1.00 3152 ## muP2P_age_c -0.58 0.13 -0.85 -0.33 1.00 3891 ## muRTSBA_accessibility1 0.53 0.85 -1.00 2.33 1.00 6327 ## muRTSBA_expenses1 -0.12 0.45 -0.99 0.76 1.00 5014 ## muRTSBA_not_owning_a_car1 -0.10 3.48 -6.90 6.77 1.00 4343 ## muRTSBA_sustainability1 0.29 0.41 -0.49 1.13 1.00 5771 ## muRTSBA_maintenance1 0.12 3.48 -6.66 7.01 1.00 4277 ## muRTSBA_parking1 0.69 0.40 -0.05 1.49 1.00 5416 ## muRTSBA_convenience1 0.28 0.35 -0.41 0.99 1.00 4943 ## muRTSBA_genderMale 0.22 0.33 -0.43 0.85 1.00 4762 ## muRTSBA_age_c 0.56 0.18 0.20 0.91 1.00 5204 ## muRTSBB_accessibility1 -0.67 0.41 -1.48 0.12 1.00 3741 ## muRTSBB_expenses1 -0.03 0.30 -0.62 0.54 1.00 4124 ## muRTSBB_not_owning_a_car1 -0.14 3.55 -7.25 6.80 1.00 3836 ## muRTSBB_sustainability1 0.31 0.26 -0.21 0.81 1.00 4554 ## muRTSBB_maintenance1 0.10 3.55 -6.93 7.18 1.00 3836 ## muRTSBB_parking1 1.11 0.25 0.61 1.61 1.00 4605 ## muRTSBB_convenience1 -0.37 0.22 -0.80 0.05 1.00 4733 ## muRTSBB_genderMale 0.35 0.22 -0.07 0.77 1.00 3708 ## muRTSBB_age_c 0.14 0.12 -0.09 0.37 1.00 4114 ## muFF_moincome -0.02 0.14 -0.32 0.22 1.00 1528 ## muFF_moeducation -0.27 0.21 -0.69 0.15 1.00 2149 ## muP2P_moincome -0.31 0.09 -0.50 -0.15 1.00 2300 ## muP2P_moeducation -0.52 0.17 -0.89 -0.22 1.00 2052 ## muRTSBA_moincome -0.10 0.14 -0.38 0.17 1.00 3049 ## muRTSBA_moeducation 0.55 0.35 -0.03 1.33 1.00 3057 ## muRTSBB_moincome -0.17 0.10 -0.38 0.01 1.00 1869 ## muRTSBB_moeducation 0.13 0.22 -0.29 0.59 1.00 1727 ## Tail_ESS ## muFF_Intercept 3108 ## muP2P_Intercept 3025 ## muRTSBA_Intercept 3118 ## muRTSBB_Intercept 2459 ## muFF_accessibility1 3296 ## muFF_expenses1 3276 ## muFF_not_owning_a_car1 2958 ## muFF_sustainability1 3115 ## muFF_maintenance1 3139 ## muFF_parking1 3210 ## muFF_convenience1 3298 ## muFF_genderMale 3378 ## muFF_age_c 3187 ## muP2P_accessibility1 3136 ## muP2P_expenses1 2857 ## muP2P_not_owning_a_car1 2960 ## muP2P_sustainability1 3385 ## muP2P_maintenance1 3040 ## muP2P_parking1 3249 ## muP2P_convenience1 3230 ## muP2P_genderMale 2959 ## muP2P_age_c 2906 ## muRTSBA_accessibility1 2960 ## muRTSBA_expenses1 2918 ## muRTSBA_not_owning_a_car1 3163 ## muRTSBA_sustainability1 3249 ## muRTSBA_maintenance1 3137 ## muRTSBA_parking1 2904 ## muRTSBA_convenience1 3424 ## muRTSBA_genderMale 2884 ## muRTSBA_age_c 3450 ## muRTSBB_accessibility1 3178 ## muRTSBB_expenses1 3592 ## muRTSBB_not_owning_a_car1 2440 ## muRTSBB_sustainability1 3074 ## muRTSBB_maintenance1 2832 ## muRTSBB_parking1 3444 ## muRTSBB_convenience1 3242 ## muRTSBB_genderMale 3137 ## muRTSBB_age_c 3353 ## muFF_moincome 2328 ## muFF_moeducation 2782 ## muP2P_moincome 2465 ## muP2P_moeducation 2631 ## muRTSBA_moincome 2961 ## muRTSBA_moeducation 2391 ## muRTSBB_moincome 2473 ## muRTSBB_moeducation 2300 ## ## Simplex Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## muFF_moincome1[1] 0.25 0.21 0.01 0.75 1.00 2911 ## muFF_moincome1[2] 0.21 0.18 0.01 0.66 1.00 3045 ## muFF_moincome1[3] 0.15 0.14 0.00 0.53 1.00 6050 ## muFF_moincome1[4] 0.16 0.15 0.00 0.55 1.00 4352 ## muFF_moincome1[5] 0.22 0.21 0.00 0.74 1.00 2038 ## muFF_moeducation1[1] 0.37 0.23 0.02 0.82 1.00 4941 ## muFF_moeducation1[2] 0.22 0.19 0.01 0.71 1.00 5056 ## muFF_moeducation1[3] 0.41 0.23 0.03 0.85 1.00 3553 ## muP2P_moincome1[1] 0.09 0.08 0.00 0.31 1.00 4503 ## muP2P_moincome1[2] 0.14 0.10 0.01 0.38 1.00 4179 ## muP2P_moincome1[3] 0.30 0.16 0.04 0.63 1.00 5276 ## muP2P_moincome1[4] 0.30 0.16 0.03 0.63 1.00 5301 ## muP2P_moincome1[5] 0.16 0.12 0.01 0.43 1.00 6716 ## muP2P_moeducation1[1] 0.21 0.15 0.01 0.55 1.00 4053 ## muP2P_moeducation1[2] 0.39 0.19 0.05 0.78 1.00 4508 ## muP2P_moeducation1[3] 0.40 0.18 0.08 0.77 1.00 5192 ## muRTSBA_moincome1[1] 0.24 0.18 0.01 0.66 1.00 5989 ## muRTSBA_moincome1[2] 0.19 0.16 0.01 0.57 1.00 5685 ## muRTSBA_moincome1[3] 0.17 0.15 0.00 0.53 1.00 6079 ## muRTSBA_moincome1[4] 0.19 0.15 0.01 0.57 1.00 6193 ## muRTSBA_moincome1[5] 0.22 0.17 0.01 0.63 1.00 5143 ## muRTSBA_moeducation1[1] 0.28 0.20 0.01 0.72 1.00 5099 ## muRTSBA_moeducation1[2] 0.35 0.23 0.02 0.82 1.00 6041 ## muRTSBA_moeducation1[3] 0.37 0.22 0.03 0.84 1.00 4643 ## muRTSBB_moincome1[1] 0.22 0.16 0.01 0.59 1.00 4826 ## muRTSBB_moincome1[2] 0.15 0.12 0.01 0.47 1.00 5049 ## muRTSBB_moincome1[3] 0.13 0.12 0.00 0.43 1.00 4828 ## muRTSBB_moincome1[4] 0.26 0.17 0.01 0.64 1.00 6050 ## muRTSBB_moincome1[5] 0.24 0.16 0.01 0.60 1.00 5554 ## muRTSBB_moeducation1[1] 0.41 0.24 0.02 0.87 1.00 5165 ## muRTSBB_moeducation1[2] 0.28 0.21 0.01 0.79 1.00 5821 ## muRTSBB_moeducation1[3] 0.31 0.22 0.01 0.82 1.00 5128 ## Tail_ESS ## muFF_moincome1[1] 2675 ## muFF_moincome1[2] 2292 ## muFF_moincome1[3] 2633 ## muFF_moincome1[4] 2370 ## muFF_moincome1[5] 3064 ## muFF_moeducation1[1] 2636 ## muFF_moeducation1[2] 2619 ## muFF_moeducation1[3] 3198 ## muP2P_moincome1[1] 2245 ## muP2P_moincome1[2] 1866 ## muP2P_moincome1[3] 2290 ## muP2P_moincome1[4] 2567 ## muP2P_moincome1[5] 2538 ## muP2P_moeducation1[1] 2670 ## muP2P_moeducation1[2] 1731 ## muP2P_moeducation1[3] 2894 ## muRTSBA_moincome1[1] 2175 ## muRTSBA_moincome1[2] 2635 ## muRTSBA_moincome1[3] 2698 ## muRTSBA_moincome1[4] 2260 ## muRTSBA_moincome1[5] 2611 ## muRTSBA_moeducation1[1] 2575 ## muRTSBA_moeducation1[2] 2445 ## muRTSBA_moeducation1[3] 2338 ## muRTSBB_moincome1[1] 2272 ## muRTSBB_moincome1[2] 2484 ## muRTSBB_moincome1[3] 2229 ## muRTSBB_moincome1[4] 2750 ## muRTSBB_moincome1[5] 2444 ## muRTSBB_moeducation1[1] 2485 ## muRTSBB_moeducation1[2] 2532 ## muRTSBB_moeducation1[3] 2803 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 3.2.4 Marginal effects plot(conditional_effects(m_first_operator, categorical = T), ask=F) 3.3 Figures for the paper 3.3.1 Panel 1 - demographics gender &lt;- plot(conditional_effects(m_first_operator, effects = &quot;gender&quot;, categorical = T))[[1]] income &lt;- plot(conditional_effects(m_first_operator, effects = &quot;income&quot;, categorical = T))[[1]] age &lt;- plot(conditional_effects(m_first_operator, effects = &quot;age_c&quot;, categorical = T))[[1]] education &lt;- plot(conditional_effects(m_first_operator, effects = &quot;education&quot;, categorical = T))[[1]] Customizing the labels gender &lt;- gender+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Gender&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) income &lt;- income+ coord_cartesian(ylim = c(0,1)) + scale_x_discrete(labels = c(&quot;&lt; 1k&quot;, &quot;1k to 2k&quot;, &quot;2k to 3k&quot;, &quot;3k to 4k&quot;, &quot;4k to 5k&quot;, &quot;&gt; 5k&quot;))+ theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+ labs(x=&quot;Income range (Euros)&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) education &lt;- education+ coord_cartesian(ylim = c(0,1)) + scale_x_discrete(labels = c(&quot;Secondary 1&quot;, &quot;Secondary 2&quot;, &quot;High School&quot;, &quot;University&quot;)) + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+ labs(x=&quot;Education&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) age &lt;- age+ coord_cartesian(ylim = c(0,1)) + theme(legend.title = element_blank(), legend.position = &quot;none&quot;) + labs(x=&quot;Age (normalized)&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) p &lt;- ((gender + age) / (income + education)) + plot_layout(guides = &quot;collect&quot;)+ plot_annotation(title = &quot;Demographic variables&quot;) p 3.3.2 Panel 2 - motivators accessibility &lt;- plot(conditional_effects(m_first_operator, effects = &quot;accessibility&quot;, categorical = T))[[1]] expenses &lt;- plot(conditional_effects(m_first_operator, effects = &quot;expenses&quot;, categorical = T))[[1]] not_owning_a_car &lt;- plot(conditional_effects(m_first_operator, effects = &quot;not_owning_a_car&quot;, categorical = T))[[1]] sustainability &lt;- plot(conditional_effects(m_first_operator, effects = &quot;sustainability&quot;, categorical = T))[[1]] maintenance &lt;- plot(conditional_effects(m_first_operator, effects = &quot;maintenance&quot;, categorical = T))[[1]] parking &lt;- plot(conditional_effects(m_first_operator, effects = &quot;parking&quot;, categorical = T))[[1]] convenience &lt;- plot(conditional_effects(m_first_operator, effects = &quot;convenience&quot;, categorical = T))[[1]] Customizing the labels accessibility &lt;- accessibility + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Accesibility&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) expenses &lt;- expenses + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ coord_cartesian(ylim = c(0,1)) + theme(axis.title.y=element_blank())+ labs(x=&quot;Expenses&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) maintenance &lt;- maintenance + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ coord_cartesian(ylim = c(0,1)) + theme(axis.title.y=element_blank())+ labs(x=&quot;Maintanence&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) not_owning_a_car &lt;- not_owning_a_car + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ coord_cartesian(ylim = c(0,1)) + theme(axis.title.y=element_blank())+ labs(x=&quot;Not owning a car&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) sustainability &lt;- sustainability + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ theme(axis.title.y=element_blank())+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Sustainability&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) parking &lt;- parking + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Parking&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) convenience &lt;- convenience + scale_x_discrete(labels = c(&quot;No&quot;, &quot;Yes&quot;))+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Convenience&quot;, fill = &quot;Business model&quot;, colour = &quot;Business model&quot;) p &lt;- ((accessibility + sustainability) / (convenience + not_owning_a_car) / (parking + expenses + maintenance)) + plot_layout(guides = &quot;collect&quot;)+ plot_annotation(title = &quot;Importance of motivators&quot;) &amp; theme(legend.position = &#39;bottom&#39;) p "],["ranking-carsharing-based-on-the-type-of-the-trip.html", "Chapter 4 Ranking carsharing based on the type of the trip 4.1 Importing the data 4.2 Helper functions 4.3 Number of people registered in at least 2 companies 4.4 Work trips 4.5 Going out for dinner trips 4.6 Daily-shopping trips 4.7 Bulk shopping trips 4.8 Recreational activity trips 4.9 Holiday trips 4.10 Creating tables and figures for the article", " Chapter 4 Ranking carsharing based on the type of the trip library(haven) library(tidyverse) library(labelled) library(bpcs) library(knitr) set.seed(3103) 4.1 Importing the data d &lt;- haven::read_sav(&quot;data/original/Users Germany.sav&quot;) 4.2 Helper functions Here we define some initial functions to help make the paired comparison. These function basically take 1 row and create a dataset with all 10 possible paired comparisons. Then it merges each of these new datasets together. # expand 1 row process_row &lt;- function(df, out, company0, company1, row){ diff01 &lt;- df[[row,company0]] - df[[row,company1]] if(!is.na(diff01)){ res&lt;-NULL if(diff01==0) res &lt;- rbinom(1,1,0.5)#if tie it is randomly solved else res &lt;- ifelse(diff01 &gt; 0 , 0, 1) out &lt;- add_row(out,company0=company0,company1=company1, win=res, user=row) } return(out) } convert2pairedcomp &lt;- function(df){ out&lt;-tribble(~company0, ~company1, ~win, ~user) i&lt;-1 for(i in seq_along(1:nrow(df))){ # print(i) # All 10 combinations out &lt;- process_row(df,out, &#39;COMB&#39;,&#39;FF&#39;,i) out &lt;- process_row(df,out, &#39;COMB&#39;,&#39;RTSB_B&#39;,i) out &lt;- process_row(df,out, &#39;COMB&#39;,&#39;P2P&#39;,i) out &lt;- process_row(df,out, &#39;COMB&#39;,&#39;RTSB_A&#39;,i) out &lt;- process_row(df,out, &#39;FF&#39;,&#39;RTSB_B&#39;,i) out &lt;- process_row(df,out, &#39;FF&#39;,&#39;P2P&#39;,i) out &lt;- process_row(df,out, &#39;FF&#39;,&#39;RTSB_A&#39;,i) out &lt;- process_row(df,out, &#39;RTSB_B&#39;,&#39;P2P&#39;,i) out &lt;- process_row(df,out, &#39;RTSB_B&#39;,&#39;RTSB_A&#39;,i) out &lt;- process_row(df,out, &#39;P2P&#39;,&#39;RTSB_A&#39;,i) } return(out) } 4.3 Number of people registered in at least 2 companies Here we just calculate how many people are registered in at least 2-5 companies (among all users) d_registered_in_2&lt;- d %&gt;% select(anbiet1, anbiet2, anbiet3, anbiet4, anbiet5, anbiet6) %&gt;% filter(!is.na(anbiet1)&amp;!is.na(anbiet2)) cat(&#39;There are:&#39;, nrow(d_registered_in_2), &#39; registered in at least 2 companies\\n&#39;) ## There are: 447 registered in at least 2 companies d_registered_in_3 &lt;- d %&gt;% select(anbiet1, anbiet2, anbiet3, anbiet4, anbiet5, anbiet6) %&gt;% filter(!is.na(anbiet1)&amp;!is.na(anbiet2)&amp;!is.na(anbiet3)) cat(&#39;There are:&#39;, nrow(d_registered_in_3), &#39; registered in at least 3 companies\\n&#39;) ## There are: 170 registered in at least 3 companies d_registered_in_4 &lt;- d %&gt;% select(anbiet1, anbiet2, anbiet3, anbiet4, anbiet5, anbiet6) %&gt;% filter(!is.na(anbiet1)&amp;!is.na(anbiet2)&amp;!is.na(anbiet3)&amp;!is.na(anbiet4)) cat(&#39;There are:&#39;, nrow(d_registered_in_4), &#39; registered in at least 4 companies\\n&#39;) ## There are: 48 registered in at least 4 companies d_registered_in_5 &lt;- d %&gt;% select(anbiet1, anbiet2, anbiet3, anbiet4, anbiet5, anbiet6) %&gt;% filter(!is.na(anbiet1)&amp;!is.na(anbiet2)&amp;!is.na(anbiet3)&amp;!is.na(anbiet4)&amp;!is.na(anbiet5)) cat(&#39;There are:&#39;, nrow(d_registered_in_5), &#39; registered in at least 5 companies\\n&#39;) ## There are: 10 registered in at least 5 companies 4.4 Work trips d_work &lt;- d %&gt;% select(v22bnd_1, v22c2g_1, v22stamo, v22driv, v22cam_1) %&gt;% rename(&#39;COMB&#39;=&#39;v22bnd_1&#39;, &#39;FF&#39; =&#39;v22c2g_1&#39;, &#39;RTSB_B&#39; = &#39;v22stamo&#39;, &#39;P2P&#39; = &#39;v22driv&#39;, &#39;RTSB_A&#39; = &#39;v22cam_1&#39;) %&gt;% mutate(COMB = as.numeric(COMB), FF = as.numeric(FF), RTSB_B = as.numeric(RTSB_B), P2P = as.numeric(P2P), RTSB_A = as.numeric(RTSB_A)) Now lets convert this to paired comparison d_work_pc &lt;- convert2pairedcomp(d_work) cat(length(unique(d_work_pc$user)), &#39; evaluated at least two companies&#39;) ## 252 evaluated at least two companies m_work &lt;- bpc(d_work_pc, player0 = &#39;company0&#39;, player1=&#39;company1&#39;, result_column = &#39;win&#39;, model_type = &#39;bt&#39;) saveRDS(m_work,file = &#39;models/m_work.RDS&#39;) plot(m_work) summary(m_work) ## Estimated baseline parameters with 95% HPD intervals: ## ## Table: (\\#tab:unnamed-chunk-38)Parameters estimates ## ## Parameter Mean Median HPD_lower HPD_higher ## --------------- ------ ------- ---------- ----------- ## lambda[COMB] -0.05 -0.08 -2.59 2.88 ## lambda[FF] 0.57 0.54 -1.86 3.59 ## lambda[RTSB_B] -0.27 -0.29 -2.96 2.52 ## lambda[P2P] -0.28 -0.29 -3.03 2.47 ## lambda[RTSB_A] 0.04 0.03 -2.59 2.94 ## NOTES: ## * A higher lambda indicates a higher team ability ## ## Posterior probabilities: ## These probabilities are calculated from the predictive posterior distribution ## for all player combinations ## ## ## Table: (\\#tab:unnamed-chunk-38)Estimated posterior probabilites ## ## i j i_beats_j j_beats_i ## ------- ------- ---------- ---------- ## COMB FF 0.35 0.65 ## COMB P2P 0.54 0.46 ## COMB RTSB_A 0.44 0.56 ## COMB RTSB_B 0.60 0.40 ## FF P2P 0.66 0.34 ## FF RTSB_A 0.62 0.38 ## FF RTSB_B 0.69 0.31 ## P2P RTSB_A 0.37 0.63 ## P2P RTSB_B 0.60 0.40 ## RTSB_A RTSB_B 0.64 0.36 ## ## Rank of the players&#39; abilities: ## The rank is based on the posterior rank distribution of the lambda parameter ## ## Table: (\\#tab:unnamed-chunk-38)Estimated posterior ranks ## ## Parameter MedianRank MeanRank StdRank ## ---------- ----------- --------- -------- ## FF 1 1.06 0.24 ## RTSB_A 2 2.72 1.08 ## COMB 3 3.07 0.95 ## P2P 4 4.10 0.94 ## RTSB_B 4 4.05 0.92 4.5 Going out for dinner trips d_dinner &lt;- d %&gt;% select(v22bnd_2, v22c2g_2, v158_a, v164_a, v22cam_2) %&gt;% rename(&#39;COMB&#39;=&#39;v22bnd_2&#39;, &#39;FF&#39; =&#39;v22c2g_2&#39;, &#39;RTSB_B&#39; = &#39;v158_a&#39;, &#39;P2P&#39; = &#39;v164_a&#39;, &#39;RTSB_A&#39; = &#39;v22cam_2&#39;) %&gt;% mutate(COMB = as.numeric(COMB), FF = as.numeric(FF), RTSB_B = as.numeric(RTSB_B), P2P = as.numeric(P2P), RTSB_A = as.numeric(RTSB_A)) Now lets convert this to paired comparison d_dinner_pc &lt;- convert2pairedcomp(d_dinner) m_dinner &lt;- bpc(d_dinner_pc, player0 = &#39;company0&#39;, player1=&#39;company1&#39;, result_column = &#39;win&#39;, model_type = &#39;bt&#39;) saveRDS(m_dinner,file = &#39;models/m_dinner.RDS&#39;) plot(m_dinner) summary(m_dinner) ## Estimated baseline parameters with 95% HPD intervals: ## ## Table: (\\#tab:unnamed-chunk-44)Parameters estimates ## ## Parameter Mean Median HPD_lower HPD_higher ## --------------- ------ ------- ---------- ----------- ## lambda[COMB] 0.21 0.20 -2.42 2.70 ## lambda[FF] 0.83 0.81 -1.64 3.51 ## lambda[RTSB_B] -0.30 -0.32 -2.76 2.39 ## lambda[P2P] -0.59 -0.60 -3.21 1.95 ## lambda[RTSB_A] -0.30 -0.31 -2.99 2.19 ## NOTES: ## * A higher lambda indicates a higher team ability ## ## Posterior probabilities: ## These probabilities are calculated from the predictive posterior distribution ## for all player combinations ## ## ## Table: (\\#tab:unnamed-chunk-44)Estimated posterior probabilites ## ## i j i_beats_j j_beats_i ## ------- ------- ---------- ---------- ## COMB FF 0.37 0.63 ## COMB P2P 0.72 0.28 ## COMB RTSB_A 0.60 0.40 ## COMB RTSB_B 0.60 0.40 ## FF P2P 0.84 0.16 ## FF RTSB_A 0.66 0.34 ## FF RTSB_B 0.80 0.20 ## P2P RTSB_A 0.52 0.48 ## P2P RTSB_B 0.41 0.59 ## RTSB_A RTSB_B 0.48 0.52 ## ## Rank of the players&#39; abilities: ## The rank is based on the posterior rank distribution of the lambda parameter ## ## Table: (\\#tab:unnamed-chunk-44)Estimated posterior ranks ## ## Parameter MedianRank MeanRank StdRank ## ---------- ----------- --------- -------- ## FF 1 1.01 0.09 ## COMB 2 2.15 0.43 ## RTSB_A 4 3.58 0.89 ## RTSB_B 4 3.71 0.77 ## P2P 5 4.55 0.68 4.6 Daily-shopping trips d_shopdaily &lt;- d %&gt;% select(v22bnd_3, v22c2g_3, v159_a, v165_a, v22cam_3) %&gt;% rename(&#39;COMB&#39;=&#39;v22bnd_3&#39;, &#39;FF&#39; =&#39;v22c2g_3&#39;, &#39;RTSB_B&#39; = &#39;v159_a&#39;, &#39;P2P&#39; = &#39;v165_a&#39;, &#39;RTSB_A&#39; = &#39;v22cam_3&#39;) %&gt;% mutate(COMB = as.numeric(COMB), FF = as.numeric(FF), RTSB_B = as.numeric(RTSB_B), P2P = as.numeric(P2P), RTSB_A = as.numeric(RTSB_A)) Now lets convert this to paired comparison d_shopdaily_pc &lt;- convert2pairedcomp(d_shopdaily) cat(length(unique(d_shopdaily_pc$user)), &#39; evaluated at least two companies&#39;) ## 252 evaluated at least two companies m_shopdaily &lt;- bpc(d_shopdaily_pc, player0 = &#39;company0&#39;, player1=&#39;company1&#39;, result_column = &#39;win&#39;, model_type = &#39;bt&#39;) saveRDS(m_shopdaily,file = &#39;models/m_shopdaily.RDS&#39;) plot(m_shopdaily) summary(m_shopdaily) ## Estimated baseline parameters with 95% HPD intervals: ## ## Table: (\\#tab:unnamed-chunk-50)Parameters estimates ## ## Parameter Mean Median HPD_lower HPD_higher ## --------------- ------ ------- ---------- ----------- ## lambda[COMB] 0.55 0.55 -2.08 2.92 ## lambda[FF] 0.25 0.26 -2.25 2.71 ## lambda[RTSB_B] 0.18 0.17 -2.35 2.61 ## lambda[P2P] -0.83 -0.83 -3.38 1.57 ## lambda[RTSB_A] 0.21 0.23 -2.41 2.61 ## NOTES: ## * A higher lambda indicates a higher team ability ## ## Posterior probabilities: ## These probabilities are calculated from the predictive posterior distribution ## for all player combinations ## ## ## Table: (\\#tab:unnamed-chunk-50)Estimated posterior probabilites ## ## i j i_beats_j j_beats_i ## ------- ------- ---------- ---------- ## COMB FF 0.62 0.38 ## COMB P2P 0.77 0.23 ## COMB RTSB_A 0.65 0.35 ## COMB RTSB_B 0.61 0.39 ## FF P2P 0.76 0.24 ## FF RTSB_A 0.53 0.47 ## FF RTSB_B 0.51 0.49 ## P2P RTSB_A 0.24 0.76 ## P2P RTSB_B 0.31 0.69 ## RTSB_A RTSB_B 0.54 0.46 ## ## Rank of the players&#39; abilities: ## The rank is based on the posterior rank distribution of the lambda parameter ## ## Table: (\\#tab:unnamed-chunk-50)Estimated posterior ranks ## ## Parameter MedianRank MeanRank StdRank ## ---------- ----------- --------- -------- ## COMB 1 1.37 0.71 ## FF 3 2.71 0.78 ## RTSB_A 3 2.82 1.14 ## RTSB_B 3 3.11 0.89 ## P2P 5 5.00 0.04 4.7 Bulk shopping trips d_shopbulk &lt;- d %&gt;% select(v22bnd_4, v22c2g_4, v160_a, v166_a, v22cam_4) %&gt;% rename(&#39;COMB&#39;=&#39;v22bnd_4&#39;, &#39;FF&#39; =&#39;v22c2g_4&#39;, &#39;RTSB_B&#39; = &#39;v160_a&#39;, &#39;P2P&#39; = &#39;v166_a&#39;, &#39;RTSB_A&#39; = &#39;v22cam_4&#39;) %&gt;% mutate(COMB = as.numeric(COMB), FF = as.numeric(FF), RTSB_B = as.numeric(RTSB_B), P2P = as.numeric(P2P), RTSB_A = as.numeric(RTSB_A)) Now lets convert this to paired comparison d_shopbulk_pc &lt;- convert2pairedcomp(d_shopbulk) cat(length(unique(d_shopbulk_pc$user)), &#39; evaluated at least two companies&#39;) ## 252 evaluated at least two companies m_shopbulk &lt;- bpc(d_shopbulk_pc, player0 = &#39;company0&#39;, player1=&#39;company1&#39;, result_column = &#39;win&#39;, model_type = &#39;bt&#39;) saveRDS(m_shopbulk,file = &#39;models/m_shopbulk.RDS&#39;) plot(m_shopbulk) summary(m_shopbulk) ## Estimated baseline parameters with 95% HPD intervals: ## ## Table: (\\#tab:unnamed-chunk-56)Parameters estimates ## ## Parameter Mean Median HPD_lower HPD_higher ## --------------- ------ ------- ---------- ----------- ## lambda[COMB] 0.31 0.32 -2.20 2.93 ## lambda[FF] -0.84 -0.83 -3.31 1.75 ## lambda[RTSB_B] 1.00 1.01 -1.50 3.60 ## lambda[P2P] -0.73 -0.72 -3.25 1.83 ## lambda[RTSB_A] 0.26 0.28 -2.38 2.77 ## NOTES: ## * A higher lambda indicates a higher team ability ## ## Posterior probabilities: ## These probabilities are calculated from the predictive posterior distribution ## for all player combinations ## ## ## Table: (\\#tab:unnamed-chunk-56)Estimated posterior probabilites ## ## i j i_beats_j j_beats_i ## ------- ------- ---------- ---------- ## COMB FF 0.76 0.24 ## COMB P2P 0.71 0.29 ## COMB RTSB_A 0.47 0.53 ## COMB RTSB_B 0.36 0.64 ## FF P2P 0.46 0.54 ## FF RTSB_A 0.25 0.75 ## FF RTSB_B 0.15 0.85 ## P2P RTSB_A 0.23 0.77 ## P2P RTSB_B 0.13 0.87 ## RTSB_A RTSB_B 0.33 0.67 ## ## Rank of the players&#39; abilities: ## The rank is based on the posterior rank distribution of the lambda parameter ## ## Table: (\\#tab:unnamed-chunk-56)Estimated posterior ranks ## ## Parameter MedianRank MeanRank StdRank ## ---------- ----------- --------- -------- ## RTSB_B 1 1.05 0.22 ## COMB 2 2.45 0.51 ## RTSB_A 3 2.50 0.58 ## P2P 4 4.31 0.47 ## FF 5 4.69 0.46 4.8 Recreational activity trips d_recreational &lt;- d %&gt;% select(v22bnd_5, v22c2g_5, v161_a, v167_a, v22cam_5) %&gt;% rename(&#39;COMB&#39;=&#39;v22bnd_5&#39;, &#39;FF&#39; =&#39;v22c2g_5&#39;, &#39;RTSB_B&#39; = &#39;v161_a&#39;, &#39;P2P&#39; = &#39;v167_a&#39;, &#39;RTSB_A&#39; = &#39;v22cam_5&#39;) %&gt;% mutate(COMB = as.numeric(COMB), FF = as.numeric(FF), RTSB_B = as.numeric(RTSB_B), P2P = as.numeric(P2P), RTSB_A = as.numeric(RTSB_A)) Now lets convert this to paired comparison d_recreational_pc &lt;- convert2pairedcomp(d_recreational) cat(length(unique(d_recreational_pc$user)), &#39; evaluated at least two companies&#39;) ## 252 evaluated at least two companies m_recreational &lt;- bpc(d_recreational_pc, player0 = &#39;company0&#39;, player1=&#39;company1&#39;, result_column = &#39;win&#39;, model_type = &#39;bt&#39;) saveRDS(m_recreational,file = &#39;models/m_recreational.RDS&#39;) plot(m_recreational) summary(m_recreational) ## Estimated baseline parameters with 95% HPD intervals: ## ## Table: (\\#tab:unnamed-chunk-62)Parameters estimates ## ## Parameter Mean Median HPD_lower HPD_higher ## --------------- ------ ------- ---------- ----------- ## lambda[COMB] 0.46 0.46 -2.40 3.21 ## lambda[FF] -1.50 -1.51 -4.29 1.26 ## lambda[RTSB_B] 0.70 0.69 -2.31 3.30 ## lambda[P2P] 0.06 0.06 -2.76 2.80 ## lambda[RTSB_A] 0.15 0.16 -2.72 2.92 ## NOTES: ## * A higher lambda indicates a higher team ability ## ## Posterior probabilities: ## These probabilities are calculated from the predictive posterior distribution ## for all player combinations ## ## ## Table: (\\#tab:unnamed-chunk-62)Estimated posterior probabilites ## ## i j i_beats_j j_beats_i ## ------- ------- ---------- ---------- ## COMB FF 0.89 0.11 ## COMB P2P 0.62 0.38 ## COMB RTSB_A 0.62 0.38 ## COMB RTSB_B 0.49 0.51 ## FF P2P 0.13 0.87 ## FF RTSB_A 0.17 0.83 ## FF RTSB_B 0.14 0.86 ## P2P RTSB_A 0.55 0.45 ## P2P RTSB_B 0.28 0.72 ## RTSB_A RTSB_B 0.40 0.60 ## ## Rank of the players&#39; abilities: ## The rank is based on the posterior rank distribution of the lambda parameter ## ## Table: (\\#tab:unnamed-chunk-62)Estimated posterior ranks ## ## Parameter MedianRank MeanRank StdRank ## ---------- ----------- --------- -------- ## RTSB_B 1 1.40 0.65 ## COMB 2 2.19 0.88 ## RTSB_A 3 3.03 0.94 ## P2P 4 3.37 0.75 ## FF 5 5.00 0.00 4.9 Holiday trips d_holidays &lt;- d %&gt;% select(v22bnd_6, v22c2g_6, v162_a, v168_a, v22cam_6) %&gt;% rename(&#39;COMB&#39;=&#39;v22bnd_6&#39;, &#39;FF&#39; =&#39;v22c2g_6&#39;, &#39;RTSB_B&#39; = &#39;v162_a&#39;, &#39;P2P&#39; = &#39;v168_a&#39;, &#39;RTSB_A&#39; = &#39;v22cam_6&#39;) %&gt;% mutate(COMB = as.numeric(COMB), FF = as.numeric(FF), RTSB_B = as.numeric(RTSB_B), P2P = as.numeric(P2P), RTSB_A = as.numeric(RTSB_A)) Now lets convert this to paired comparison d_holidays_pc &lt;- convert2pairedcomp(d_holidays) cat(length(unique(d_holidays_pc$user)), &#39; evaluated at least two companies&#39;) ## 252 evaluated at least two companies m_holidays &lt;- bpc(d_holidays_pc, player0 = &#39;company0&#39;, player1=&#39;company1&#39;, result_column = &#39;win&#39;, model_type = &#39;bt&#39;) saveRDS(m_holidays,file = &#39;models/m_holidays.RDS&#39;) plot(m_holidays) summary(m_holidays) ## Estimated baseline parameters with 95% HPD intervals: ## ## Table: (\\#tab:unnamed-chunk-68)Parameters estimates ## ## Parameter Mean Median HPD_lower HPD_higher ## --------------- ------ ------- ---------- ----------- ## lambda[COMB] -0.50 -0.50 -3.07 2.19 ## lambda[FF] -1.95 -1.95 -4.34 0.87 ## lambda[RTSB_B] 0.32 0.32 -2.14 3.09 ## lambda[P2P] 0.94 0.92 -1.64 3.63 ## lambda[RTSB_A] 0.71 0.69 -1.77 3.48 ## NOTES: ## * A higher lambda indicates a higher team ability ## ## Posterior probabilities: ## These probabilities are calculated from the predictive posterior distribution ## for all player combinations ## ## ## Table: (\\#tab:unnamed-chunk-68)Estimated posterior probabilites ## ## i j i_beats_j j_beats_i ## ------- ------- ---------- ---------- ## COMB FF 0.75 0.25 ## COMB P2P 0.23 0.77 ## COMB RTSB_A 0.28 0.72 ## COMB RTSB_B 0.30 0.70 ## FF P2P 0.08 0.92 ## FF RTSB_A 0.08 0.92 ## FF RTSB_B 0.14 0.86 ## P2P RTSB_A 0.52 0.48 ## P2P RTSB_B 0.57 0.43 ## RTSB_A RTSB_B 0.64 0.36 ## ## Rank of the players&#39; abilities: ## The rank is based on the posterior rank distribution of the lambda parameter ## ## Table: (\\#tab:unnamed-chunk-68)Estimated posterior ranks ## ## Parameter MedianRank MeanRank StdRank ## ---------- ----------- --------- -------- ## P2P 1 1.39 0.57 ## RTSB_A 2 1.95 0.73 ## RTSB_B 3 2.68 0.58 ## COMB 4 3.98 0.13 ## FF 5 5.00 0.00 4.10 Creating tables and figures for the article Table of ranks rank_table &lt;- rbind( get_rank_of_players_df(m_work), get_rank_of_players_df(m_dinner), get_rank_of_players_df(m_shopdaily), get_rank_of_players_df(m_shopbulk), get_rank_of_players_df(m_recreational), get_rank_of_players_df(m_holidays)) colnames(rank_table) &lt;- c(&#39;Carsharing&#39;, &#39;Median&#39;, &#39;Mean&#39;, &#39;sd&#39;) rank_table$Carsharing &lt;- str_remove(rank_table$Carsharing, fixed(&#39;lambda[&#39;)) rank_table$Carsharing &lt;- str_remove(rank_table$Carsharing, fixed(&#39;]&#39;)) rank_table %&gt;% kable(caption=&quot;Rank of the types of carsharing&quot;, booktabs=T, digits =2, format = &#39;html&#39;, label=&#39;ranking-table&#39;) %&gt;% kableExtra::kable_styling() %&gt;% kableExtra::pack_rows(&quot;Work trips&quot;, 1, 5) %&gt;% kableExtra::pack_rows(&quot;Dinner trips&quot;, 6, 10) %&gt;% kableExtra::pack_rows(&quot;Daily shopping trips&quot;, 11, 15) %&gt;% kableExtra::pack_rows(&quot;Bulk shopping trips&quot;, 16, 20) %&gt;% kableExtra::pack_rows(&quot;Recreational trips&quot;, 21, 25) %&gt;% kableExtra::pack_rows(&quot;Holiday trips&quot;, 26, 30) Table 4.1: Rank of the types of carsharing Carsharing Median Mean sd Work trips FF 1 1.06 0.24 RTSB_A 2 2.74 1.07 COMB 3 3.04 0.97 P2P 4 4.07 0.95 RTSB_B 4 4.08 0.90 Dinner trips FF 1 1.01 0.09 COMB 2 2.14 0.43 RTSB_A 4 3.66 0.92 RTSB_B 4 3.66 0.77 P2P 5 4.53 0.69 Daily shopping trips COMB 1 1.36 0.69 FF 3 2.69 0.78 RTSB_A 3 2.84 1.16 RTSB_B 3 3.12 0.87 P2P 5 5.00 0.04 Bulk shopping trips RTSB_B 1 1.05 0.22 COMB 2 2.44 0.52 RTSB_A 3 2.52 0.58 P2P 4 4.31 0.47 FF 5 4.69 0.46 Recreational trips RTSB_B 1 1.39 0.64 COMB 2 2.25 0.89 RTSB_A 3 2.98 0.98 P2P 4 3.37 0.75 FF 5 5.00 0.00 Holiday trips P2P 1 1.40 0.58 RTSB_A 2 1.93 0.73 RTSB_B 3 2.68 0.58 COMB 4 3.99 0.11 FF 5 5.00 0.00 "],["psychological-predictors-of-carsharing-per-business-model.html", "Chapter 5 Psychological predictors of carsharing per business model 5.1 Importing the data 5.2 Factor analysis 5.3 Analysis and models 5.4 Figures for the paper", " Chapter 5 Psychological predictors of carsharing per business model library(psych) library(haven) library(tidyverse) library(labelled) library(brms) library(knitr) set.seed(3103) 5.1 Importing the data d &lt;- haven::read_sav(&quot;data/original/Users Germany.sav&quot;) Selecting the relevant variables for this analysis. Let’s convert everything to numeric to get rid of the labels and process some of the other variables d2 &lt;- as.data.frame(sapply(d1, as.numeric)) #gender d2$gender &lt;- na_if(d2$gender, 3)#there are only 3 cases of other d2$gender&lt;-as.character(d2$gender) d2$gender &lt;- dplyr::recode(d2$gender, &#39;1&#39;=&#39;Male&#39;, &#39;2&#39;=&#39;Female&#39;, &#39;3&#39;=&#39;Other&#39;) d2$gender &lt;- as.factor(d2$gender) #age d2$age &lt;- 2019 - d2$age d2$age_c &lt;- scale(d2$age) #income d2$income &lt;- na_if(d2$income, 9) d2$income &lt;- as.character(d2$income) income_order &lt;-c(&#39;less_1000&#39;, &#39;1000_to_2000&#39;, &#39;2000_to_3000&#39;, &#39;3000_to_4000&#39;, &#39;4000_to_5000&#39;, &#39;greater_5000&#39;) d2$income &lt;- dplyr::recode(d2$income, &#39;1&#39;=&#39;less_1000&#39;, &#39;2&#39;=&#39;1000_to_2000&#39;, &#39;3&#39;=&#39;2000_to_3000&#39;, &#39;4&#39;=&#39;3000_to_4000&#39;, &#39;5&#39;=&#39;4000_to_5000&#39;, &#39;6&#39;=&#39;greater_5000&#39;) d2$income &lt;- factor(d2$income, levels = income_order, ordered = T) #education d2$education &lt;- na_if(d2$education, 9) d2$education &lt;- as.character(d2$education) education_order &lt;-c(&#39;SecondarySchool_1&#39;, &#39;SecondarySchool_2&#39;, &#39;Highschool&#39;, &#39;University&#39;) d2$education &lt;- dplyr::recode(d2$education, &#39;1&#39;=&#39;SecondarySchool_1&#39;, &#39;2&#39;=&#39;SecondarySchool_2&#39;, &#39;3&#39;=&#39;Highschool&#39;, &#39;4&#39;=&#39;University&#39;) d2$education &lt;- factor(d2$education, levels = education_order, ordered = T) Finally let’s consider only the complete cases in the predictors dropna_cols &lt;-c( #habits &#39;habit_q1&#39;, &#39;habit_q2&#39;, &#39;habit_q3&#39;, &#39;habit_q4&#39;, &#39;habit_q5&#39;, &#39;habit_q6&#39;, &#39;habit_q7&#39;, &#39;habit_q8&#39;, #climate morality &#39;climate_q1&#39;, &#39;climate_q2&#39;, &#39;climate_q3&#39;, &#39;climate_q4&#39;, &#39;climate_q5&#39;, #subjective norms &#39;subj_q1&#39;, &#39;subj_q2&#39;, &#39;subj_q3&#39;, #trust &#39;trust_q1&#39;, &#39;trust_q2&#39;, &#39;trust_q3&#39;, #control &#39;control_q1&#39;, &#39;control_q2&#39;, &#39;control_q3&#39;, &#39;control_q4&#39;, &#39;control_q5&#39;, &#39;control_q6&#39;, #others &#39;age_c&#39;, &#39;income&#39;, &#39;education&#39;, &#39;gender&#39; ) d3 &lt;- tidyr::drop_na(d2, tidyselect::any_of(dropna_cols)) We moved from 1121 cases to 762 cases when selecting only complete cases there. 5.2 Factor analysis To do a factor analysis with ordinal values we need to do a polychoric factor analysis or a non-linear FA. In this case we will do a polychoric factor analysis 5.2.1 Habits habits &lt;- d3 %&gt;% select(starts_with(&#39;habit&#39;)) Getting the scree plot #Getting the polychoric correlation habits_poly_cor &lt;- polychoric(habits) fa.parallel(habits, fa=&#39;fa&#39;, cor=&#39;poly&#39;) ## Parallel analysis suggests that the number of factors = 4 and the number of components = NA habits_model = fa(habits, nfactor=1, cor=&quot;poly&quot;, fm=&quot;mle&quot;, rotate = &quot;none&quot;) Showing the loadings of the factor analysis print(habits_model) ## Factor Analysis using method = ml ## Call: fa(r = habits, nfactors = 1, rotate = &quot;none&quot;, fm = &quot;mle&quot;, cor = &quot;poly&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## ML1 h2 u2 com ## habit_q1 0.74 0.54 0.46 1 ## habit_q2 0.64 0.41 0.59 1 ## habit_q3 0.77 0.59 0.41 1 ## habit_q4 0.81 0.65 0.35 1 ## habit_q5 0.65 0.42 0.58 1 ## habit_q6 0.50 0.25 0.75 1 ## habit_q7 0.61 0.37 0.63 1 ## habit_q8 0.69 0.48 0.52 1 ## ## ML1 ## SS loadings 3.70 ## Proportion Var 0.46 ## ## Mean item complexity = 1 ## Test of the hypothesis that 1 factor is sufficient. ## ## The degrees of freedom for the null model are 28 and the objective function was 3.42 with Chi Square of 2577.99 ## The degrees of freedom for the model are 20 and the objective function was 0.4 ## ## The root mean square of the residuals (RMSR) is 0.07 ## The df corrected root mean square of the residuals is 0.08 ## ## The harmonic number of observations is 759 with the empirical chi square 180.47 with prob &lt; 7.9e-28 ## The total number of observations was 759 with Likelihood Chi Square = 298.63 with prob &lt; 1.5e-51 ## ## Tucker Lewis Index of factoring reliability = 0.847 ## RMSEA index = 0.135 and the 90 % confidence intervals are 0.122 0.149 ## BIC = 165.99 ## Fit based upon off diagonal values = 0.98 ## Measures of factor score adequacy ## ML1 ## Correlation of (regression) scores with factors 0.94 ## Multiple R square of scores with factors 0.89 ## Minimum correlation of possible factor scores 0.77 5.2.2 Climate climate &lt;- d3 %&gt;% select(starts_with(&#39;climate&#39;)) Getting the scree plot #Getting the polychoric correlation climate_poly_cor &lt;- polychoric(climate) fa.parallel(climate, fa=&#39;fa&#39;, cor=&#39;poly&#39;) ## Parallel analysis suggests that the number of factors = 2 and the number of components = NA climate_model = fa(climate, nfactor=1, cor=&quot;poly&quot;, fm=&quot;mle&quot;, rotate = &quot;none&quot;) Showing the loadings of the factor analysis print(climate_model) ## Factor Analysis using method = ml ## Call: fa(r = climate, nfactors = 1, rotate = &quot;none&quot;, fm = &quot;mle&quot;, cor = &quot;poly&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## ML1 h2 u2 com ## climate_q1 0.91 0.84 0.16 1 ## climate_q2 0.86 0.74 0.26 1 ## climate_q3 0.74 0.55 0.45 1 ## climate_q4 0.64 0.41 0.59 1 ## climate_q5 0.56 0.31 0.69 1 ## ## ML1 ## SS loadings 2.84 ## Proportion Var 0.57 ## ## Mean item complexity = 1 ## Test of the hypothesis that 1 factor is sufficient. ## ## The degrees of freedom for the null model are 10 and the objective function was 3.12 with Chi Square of 2356.35 ## The degrees of freedom for the model are 5 and the objective function was 0.69 ## ## The root mean square of the residuals (RMSR) is 0.13 ## The df corrected root mean square of the residuals is 0.19 ## ## The harmonic number of observations is 759 with the empirical chi square 272.32 with prob &lt; 8.9e-57 ## The total number of observations was 759 with Likelihood Chi Square = 520.41 with prob &lt; 3.1e-110 ## ## Tucker Lewis Index of factoring reliability = 0.56 ## RMSEA index = 0.369 and the 90 % confidence intervals are 0.342 0.396 ## BIC = 487.25 ## Fit based upon off diagonal values = 0.95 ## Measures of factor score adequacy ## ML1 ## Correlation of (regression) scores with factors 0.96 ## Multiple R square of scores with factors 0.91 ## Minimum correlation of possible factor scores 0.82 5.2.3 Subjective norms subj &lt;- d3 %&gt;% select(starts_with(&#39;subj&#39;)) Getting the scree plot #Getting the polychoric correlation subj_poly_cor &lt;- polychoric(subj) fa.parallel(subj, fa=&#39;fa&#39;, cor=&#39;poly&#39;) ## Parallel analysis suggests that the number of factors = 1 and the number of components = NA subj_model = fa(subj, nfactor=1, cor=&quot;poly&quot;, fm=&quot;mle&quot;, rotate = &quot;none&quot;) Showing the loadings of the factor analysis print(subj_model) ## Factor Analysis using method = ml ## Call: fa(r = subj, nfactors = 1, rotate = &quot;none&quot;, fm = &quot;mle&quot;, cor = &quot;poly&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## ML1 h2 u2 com ## subj_q1 0.97 0.946 0.054 1 ## subj_q2 0.95 0.910 0.090 1 ## subj_q3 0.19 0.036 0.964 1 ## ## ML1 ## SS loadings 1.89 ## Proportion Var 0.63 ## ## Mean item complexity = 1 ## Test of the hypothesis that 1 factor is sufficient. ## ## The degrees of freedom for the null model are 3 and the objective function was 2.01 with Chi Square of 1518.13 ## The degrees of freedom for the model are 0 and the objective function was 0 ## ## The root mean square of the residuals (RMSR) is 0 ## The df corrected root mean square of the residuals is NA ## ## The harmonic number of observations is 759 with the empirical chi square 0 with prob &lt; NA ## The total number of observations was 759 with Likelihood Chi Square = 0 with prob &lt; NA ## ## Tucker Lewis Index of factoring reliability = -Inf ## Fit based upon off diagonal values = 1 ## Measures of factor score adequacy ## ML1 ## Correlation of (regression) scores with factors 0.98 ## Multiple R square of scores with factors 0.97 ## Minimum correlation of possible factor scores 0.93 5.2.4 Trust trust &lt;- d3 %&gt;% select(starts_with(&#39;trust&#39;)) Getting the scree plot #Getting the polychoric correlation trust_poly_cor &lt;- polychoric(trust) fa.parallel(trust, fa=&#39;fa&#39;, cor=&#39;poly&#39;) ## Parallel analysis suggests that the number of factors = 1 and the number of components = NA trust_model = fa(trust, nfactor=1, cor=&quot;poly&quot;, fm=&quot;mle&quot;, rotate = &quot;none&quot;) Showing the loadings of the factor analysis print(trust_model) ## Factor Analysis using method = ml ## Call: fa(r = trust, nfactors = 1, rotate = &quot;none&quot;, fm = &quot;mle&quot;, cor = &quot;poly&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## ML1 h2 u2 com ## trust_q1 0.91 0.83 0.17 1 ## trust_q2 0.92 0.85 0.15 1 ## trust_q3 0.90 0.81 0.19 1 ## ## ML1 ## SS loadings 2.49 ## Proportion Var 0.83 ## ## Mean item complexity = 1 ## Test of the hypothesis that 1 factor is sufficient. ## ## The degrees of freedom for the null model are 3 and the objective function was 2.57 with Chi Square of 1944.83 ## The degrees of freedom for the model are 0 and the objective function was 0 ## ## The root mean square of the residuals (RMSR) is 0 ## The df corrected root mean square of the residuals is NA ## ## The harmonic number of observations is 759 with the empirical chi square 0 with prob &lt; NA ## The total number of observations was 759 with Likelihood Chi Square = 0 with prob &lt; NA ## ## Tucker Lewis Index of factoring reliability = -Inf ## Fit based upon off diagonal values = 1 ## Measures of factor score adequacy ## ML1 ## Correlation of (regression) scores with factors 0.97 ## Multiple R square of scores with factors 0.94 ## Minimum correlation of possible factor scores 0.87 5.2.5 Control control &lt;- d3 %&gt;% select(starts_with(&#39;control&#39;)) Getting the scree plot #Getting the polychoric correlation control_poly_cor &lt;- polychoric(control) fa.parallel(control, fa=&#39;fa&#39;, cor=&#39;poly&#39;) ## Parallel analysis suggests that the number of factors = 3 and the number of components = NA control_model = fa(control, nfactor=1, cor=&quot;poly&quot;, fm=&quot;mle&quot;, rotate = &quot;none&quot;) Showing the loadings of the factor analysis print(control_model) ## Factor Analysis using method = ml ## Call: fa(r = control, nfactors = 1, rotate = &quot;none&quot;, fm = &quot;mle&quot;, cor = &quot;poly&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## ML1 h2 u2 com ## control_q1 0.95 0.910 0.090 1 ## control_q2 0.96 0.917 0.083 1 ## control_q3 0.32 0.101 0.899 1 ## control_q4 0.34 0.116 0.884 1 ## control_q5 0.24 0.055 0.945 1 ## control_q6 -0.22 0.047 0.953 1 ## ## ML1 ## SS loadings 2.15 ## Proportion Var 0.36 ## ## Mean item complexity = 1 ## Test of the hypothesis that 1 factor is sufficient. ## ## The degrees of freedom for the null model are 15 and the objective function was 2.97 with Chi Square of 2245.18 ## The degrees of freedom for the model are 9 and the objective function was 0.86 ## ## The root mean square of the residuals (RMSR) is 0.22 ## The df corrected root mean square of the residuals is 0.28 ## ## The harmonic number of observations is 759 with the empirical chi square 1088.58 with prob &lt; 1.3e-228 ## The total number of observations was 759 with Likelihood Chi Square = 648.57 with prob &lt; 7.8e-134 ## ## Tucker Lewis Index of factoring reliability = 0.522 ## RMSEA index = 0.306 and the 90 % confidence intervals are 0.286 0.326 ## BIC = 588.88 ## Fit based upon off diagonal values = 0.7 ## Measures of factor score adequacy ## ML1 ## Correlation of (regression) scores with factors 0.98 ## Multiple R square of scores with factors 0.96 ## Minimum correlation of possible factor scores 0.91 5.2.6 Table for the Lambda’s habits_lambda &lt;- psych::guttman(habits_poly_cor$rho) climate_lambda &lt;- psych::guttman(climate_poly_cor$rho) subj_lambda &lt;- psych::guttman(subj_poly_cor$rho) trust_lambda &lt;- psych::guttman(trust_poly_cor$rho) control_lambda &lt;- psych::guttman(control_poly_cor$rho) lambda &lt;- data.frame(Lambda=c(&quot;Chronbach&#39;s Alpha (Lambda 3)&quot;, &quot;Lambda 4&quot;), Habits = c(habits_lambda$lambda.3, habits_lambda$lambda.4), Climate = c(climate_lambda$lambda.3, climate_lambda$lambda.4), &quot;Subjective&quot; = c(subj_lambda$lambda.3, subj_lambda$lambda.4), Trust = c(trust_lambda$lambda.3, trust_lambda$lambda.4), Control = c(control_lambda$lambda.3, control_lambda$lambda.4)) lambda %&gt;% kable(caption=&quot;Values of the Lambda 3 and Lambda 4 of Guttman for the psychological predictors&quot;, digits = 2, format=&#39;html&#39;, booktabs=T, label=&quot;rq4-lambda&quot;) Table 5.1: Values of the Lambda 3 and Lambda 4 of Guttman for the psychological predictors Lambda Habits Climate Subjective Trust Control Chronbach’s Alpha (Lambda 3) 0.87 0.87 0.69 0.94 0.58 Lambda 4 0.91 0.90 0.80 0.84 0.89 5.2.7 Adding the FA scores to data frame Now we need to add to the data frame the actual scores obtained by the FA add_scores_to_df &lt;- function(df, fa_model,name){ scores&lt;- as.data.frame(fa_model$scores) n &lt;- ncol(scores) names_col&lt;-NULL if(n&gt;1) names_col &lt;- paste(rep(&#39;fa_&#39;, n), rep(name, n), seq(1,n), sep = &quot;&quot;) else names_col &lt;- paste(&#39;fa_&#39;,name,sep=&quot;&quot;) colnames(scores) &lt;- names_col out &lt;- cbind(df,scores) return(out) } d3 &lt;- add_scores_to_df(d3, habits_model, &#39;habits&#39;) d3 &lt;- add_scores_to_df(d3, climate_model, &#39;climate&#39;) d3 &lt;- add_scores_to_df(d3, subj_model, &#39;subj&#39;) d3 &lt;- add_scores_to_df(d3, trust_model, &#39;trust&#39;) d3 &lt;- add_scores_to_df(d3, control_model, &#39;control&#39;) 5.2.8 Selecting only the relevant variables now d4 &lt;- d3 %&gt;% select( FF, RTSB_B, COMB, RTSB_A, P2P, starts_with(&#39;fa&#39;), age_c, education, gender, income ) 5.3 Analysis and models Now we are going to do the same analysis for each car sharing type company We are using the same weakly informative priors for all models. For the monotonic predictors we are using the default priors where the distance is the same between each item in the income and education scale priors&lt;-c(set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;fa_habits&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;fa_climate&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;fa_subj&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;fa_trust&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;fa_control&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;age_c&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;genderMale&quot;)) priors0&lt;-c(set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;age_c&quot;), set_prior(&quot;normal(0,5)&quot;, class = &quot;b&quot;, coef = &quot;genderMale&quot;)) 5.3.1 FF d_ff &lt;- d4 %&gt;% select(FF, starts_with(&#39;fa&#39;), age_c, gender, education, income) %&gt;% drop_na() d_ff$FF &lt;- as.ordered(d_ff$FF) Ordinal regression with monotonic predictors m_ff &lt;- brm(FF ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education), data = d_ff, prior = priors, family = cumulative(), cores=4 ) m_ff0 &lt;- brm(FF ~ gender + mo(income) + age_c + mo(education), data = d_ff, prior = priors0, family = cumulative(), cores=4 ) saveRDS(m_ff0, &#39;models/m_ff0.RDS&#39;) saveRDS(m_ff, &#39;models/m_ff.RDS&#39;) Now we can get the summary of the model summary(m_ff) ## Family: cumulative ## Links: mu = logit; disc = identity ## Formula: FF ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education) ## Data: d_ff (Number of observations: 557) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept[1] -3.11 0.53 -4.04 -1.86 1.00 1509 1290 ## Intercept[2] -1.49 0.52 -2.36 -0.26 1.00 1566 1399 ## Intercept[3] -0.63 0.52 -1.50 0.62 1.00 1560 1350 ## Intercept[4] -0.33 0.52 -1.19 0.92 1.00 1545 1335 ## fa_habits -0.47 0.09 -0.64 -0.30 1.00 4791 3233 ## fa_climate -0.05 0.09 -0.21 0.12 1.00 4281 3031 ## fa_subj -0.01 0.09 -0.20 0.17 1.00 4740 2996 ## fa_trust 0.13 0.10 -0.07 0.32 1.00 4125 3084 ## fa_control -0.55 0.09 -0.73 -0.37 1.00 4246 3221 ## genderMale -0.37 0.17 -0.71 -0.03 1.00 4448 2973 ## age_c 0.57 0.10 0.38 0.77 1.00 4618 3072 ## moincome -0.10 0.06 -0.21 0.02 1.00 3328 2603 ## moeducation 0.04 0.18 -0.26 0.48 1.00 1444 1219 ## ## Simplex Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## moincome1[1] 0.16 0.14 0.00 0.51 1.00 4038 2233 ## moincome1[2] 0.14 0.12 0.00 0.47 1.00 4071 1642 ## moincome1[3] 0.16 0.14 0.00 0.51 1.00 4349 2001 ## moincome1[4] 0.25 0.18 0.01 0.63 1.00 4505 2696 ## moincome1[5] 0.28 0.19 0.01 0.69 1.00 4851 2742 ## moeducation1[1] 0.44 0.27 0.02 0.92 1.00 1857 2159 ## moeducation1[2] 0.30 0.23 0.01 0.82 1.00 2612 2266 ## moeducation1[3] 0.26 0.22 0.01 0.78 1.00 2912 2943 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## disc 1.00 0.00 1.00 1.00 1.00 4000 4000 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 5.3.1.1 Comparing the two models WAIC(m_ff) ## ## Computed from 4000 by 557 log-likelihood matrix ## ## Estimate SE ## elpd_waic -737.8 17.9 ## p_waic 14.0 0.6 ## waic 1475.6 35.8 WAIC(m_ff0) ## ## Computed from 4000 by 557 log-likelihood matrix ## ## Estimate SE ## elpd_waic -766.8 16.0 ## p_waic 8.9 0.4 ## waic 1533.7 32.1 5.3.1.2 Marginal effects In these sequence of plots we plot the conditional effects on how changing one variable impacts the probability of choosing one of the five items (1-5) in the frequency of using a carsharing type/company plot(conditional_effects(m_ff, categorical = T), ask=F) 5.3.2 RTSB_A d_rtsba &lt;- d4 %&gt;% select(RTSB_A, starts_with(&#39;fa&#39;), age_c, gender, education, income) %&gt;% drop_na() d_rtsba$RTSB_A &lt;- as.ordered(d_rtsba$RTSB_A) Ordinal regression with monotonic predictors m_rtsba &lt;- brm(RTSB_A ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education), data = d_rtsba, prior = priors, family = cumulative(), cores=4 ) saveRDS(m_rtsba, &#39;models/m_rtsba.RDS&#39;) m_rtsba0 &lt;- brm(RTSB_A ~ gender + mo(income) + age_c + mo(education), data = d_rtsba, prior = priors0, family = cumulative(), cores=4 ) saveRDS(m_rtsba0, &#39;models/m_rtsba0.RDS&#39;) Now we can get the summary of the model summary(m_rtsba) ## Family: cumulative ## Links: mu = logit; disc = identity ## Formula: RTSB_A ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education) ## Data: d_rtsba (Number of observations: 181) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept[1] -4.38 0.91 -6.27 -2.70 1.00 2858 2544 ## Intercept[2] -2.77 0.85 -4.56 -1.19 1.00 2953 2770 ## Intercept[3] -1.94 0.83 -3.67 -0.37 1.00 3019 2763 ## Intercept[4] -1.53 0.83 -3.26 -0.01 1.00 2940 2680 ## fa_habits 0.73 0.23 0.30 1.19 1.00 6025 3130 ## fa_climate -0.07 0.23 -0.53 0.38 1.00 4635 3271 ## fa_subj -0.33 0.19 -0.72 0.03 1.00 4852 3051 ## fa_trust 0.02 0.21 -0.38 0.42 1.00 4876 2956 ## fa_control -0.85 0.20 -1.26 -0.46 1.00 5395 2919 ## genderMale 0.32 0.38 -0.44 1.06 1.00 5387 3013 ## age_c -0.84 0.19 -1.22 -0.47 1.00 5067 2885 ## moincome -0.01 0.19 -0.32 0.44 1.00 2329 2409 ## moeducation -0.47 0.28 -1.05 0.04 1.00 2902 2605 ## ## Simplex Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## moincome1[1] 0.25 0.22 0.01 0.77 1.00 2761 2479 ## moincome1[2] 0.18 0.15 0.00 0.57 1.00 5176 2203 ## moincome1[3] 0.20 0.17 0.01 0.62 1.00 4002 2622 ## moincome1[4] 0.18 0.15 0.01 0.57 1.00 5357 3045 ## moincome1[5] 0.20 0.16 0.01 0.61 1.00 4471 3077 ## moeducation1[1] 0.27 0.20 0.01 0.73 1.00 4755 2735 ## moeducation1[2] 0.35 0.23 0.01 0.84 1.00 4532 2190 ## moeducation1[3] 0.38 0.22 0.02 0.84 1.00 3849 2140 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## disc 1.00 0.00 1.00 1.00 1.00 4000 4000 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 5.3.2.1 Comparing the two models WAIC(m_rtsba) ## ## Computed from 4000 by 181 log-likelihood matrix ## ## Estimate SE ## elpd_waic -176.6 14.2 ## p_waic 14.6 1.6 ## waic 353.3 28.4 ## ## 3 (1.7%) p_waic estimates greater than 0.4. We recommend trying loo instead. WAIC(m_rtsba0) ## ## Computed from 4000 by 181 log-likelihood matrix ## ## Estimate SE ## elpd_waic -189.8 13.7 ## p_waic 8.6 0.8 ## waic 379.5 27.4 ## ## 1 (0.6%) p_waic estimates greater than 0.4. We recommend trying loo instead. 5.3.2.2 Marginal effects In these sequence of plots we plot the conditional effects on how changing one variable impacts the probability of choosing one of the five items (1-5) in the frequency of using a carsharing type/company plot(conditional_effects(m_rtsba, categorical = T), ask=F) 5.3.3 RTSB_B d_rtsbb &lt;- d4 %&gt;% select(RTSB_B, starts_with(&#39;fa&#39;), age_c, gender, education, income) %&gt;% drop_na() d_rtsbb$RTSB_B &lt;- as.ordered(d_rtsbb$RTSB_B) Ordinal regression with monotonic predictors m_rtsbb &lt;- brm(RTSB_B ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education), data = d_rtsbb, prior = priors, family = cumulative(), cores=4 ) saveRDS(m_rtsbb, &#39;models/m_rtsbb.RDS&#39;) m_rtsbb0 &lt;- brm(RTSB_B ~ gender + mo(income) + age_c + mo(education), data = d_rtsbb, prior = priors0, family = cumulative(), cores=4 ) saveRDS(m_rtsbb0, &#39;models/m_rtsbb0.RDS&#39;) Now we can get the summary of the model summary(m_rtsbb) ## Family: cumulative ## Links: mu = logit; disc = identity ## Formula: RTSB_B ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education) ## Data: d_rtsbb (Number of observations: 395) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept[1] -3.99 0.61 -5.26 -2.85 1.00 2038 1770 ## Intercept[2] -1.63 0.57 -2.88 -0.58 1.00 2208 1749 ## Intercept[3] -0.74 0.56 -1.99 0.30 1.00 2239 1789 ## Intercept[4] -0.49 0.56 -1.73 0.56 1.00 2262 1814 ## fa_habits 0.31 0.12 0.08 0.54 1.00 4955 2809 ## fa_climate -0.08 0.12 -0.31 0.16 1.00 4575 2724 ## fa_subj -0.12 0.11 -0.35 0.10 1.00 4896 3156 ## fa_trust -0.34 0.12 -0.58 -0.10 1.00 5227 2938 ## fa_control -0.15 0.10 -0.35 0.05 1.00 6011 3230 ## genderMale -0.19 0.20 -0.57 0.20 1.00 5634 3248 ## age_c -0.43 0.12 -0.65 -0.19 1.00 4273 2912 ## moincome -0.07 0.08 -0.21 0.09 1.00 3785 2621 ## moeducation -0.15 0.20 -0.58 0.23 1.00 1948 1586 ## ## Simplex Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## moincome1[1] 0.22 0.17 0.01 0.62 1.00 4658 2247 ## moincome1[2] 0.19 0.16 0.01 0.57 1.00 5588 2388 ## moincome1[3] 0.23 0.17 0.01 0.63 1.00 3949 2271 ## moincome1[4] 0.17 0.14 0.01 0.52 1.00 4960 2594 ## moincome1[5] 0.19 0.15 0.01 0.57 1.00 6145 2786 ## moeducation1[1] 0.38 0.24 0.02 0.86 1.00 3664 2567 ## moeducation1[2] 0.26 0.21 0.01 0.77 1.00 4411 2886 ## moeducation1[3] 0.36 0.24 0.01 0.86 1.00 3816 2917 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## disc 1.00 0.00 1.00 1.00 1.00 4000 4000 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 5.3.3.1 Comparing the two models WAIC(m_rtsbb) ## ## Computed from 4000 by 395 log-likelihood matrix ## ## Estimate SE ## elpd_waic -510.8 14.8 ## p_waic 14.4 0.8 ## waic 1021.6 29.6 WAIC(m_rtsbb0) ## ## Computed from 4000 by 395 log-likelihood matrix ## ## Estimate SE ## elpd_waic -522.0 13.5 ## p_waic 8.5 0.4 ## waic 1044.1 27.0 5.3.3.2 Marginal effects In these sequence of plots we plot the conditional effects on how changing one variable impacts the probability of choosing one of the five items (1-5) in the frequency of using a carsharing type/company plot(conditional_effects(m_rtsbb, categorical = T), ask=F) 5.3.4 COMB d_comb &lt;- d4 %&gt;% select(COMB, starts_with(&#39;fa&#39;), age_c, gender, education, income) %&gt;% drop_na() d_comb$COMB &lt;- as.ordered(d_comb$COMB) Ordinal regression with monotonic predictors m_comb &lt;- brm(COMB ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education), data = d_comb, prior = priors, family = cumulative(), cores=4 ) saveRDS(m_comb, &#39;models/m_comb.RDS&#39;) m_comb0 &lt;- brm(COMB ~ gender + mo(income) + age_c + mo(education), data = d_comb, prior = priors0, family = cumulative(), cores=4 ) saveRDS(m_comb0, &#39;models/m_comb0.RDS&#39;) Now we can get the summary of the model summary(m_comb) ## Family: cumulative ## Links: mu = logit; disc = identity ## Formula: COMB ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education) ## Data: d_comb (Number of observations: 235) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept[1] -1.72 0.91 -3.39 0.18 1.00 2148 2368 ## Intercept[2] 0.03 0.90 -1.65 1.93 1.00 2070 2290 ## Intercept[3] 0.76 0.91 -0.90 2.68 1.00 2106 2144 ## Intercept[4] 1.14 0.91 -0.51 3.05 1.00 2093 2245 ## fa_habits 0.05 0.15 -0.24 0.35 1.00 4750 3084 ## fa_climate -0.19 0.14 -0.46 0.06 1.00 4216 3091 ## fa_subj -0.01 0.14 -0.27 0.27 1.00 4315 2678 ## fa_trust -0.19 0.16 -0.50 0.13 1.00 4042 2901 ## fa_control -0.29 0.13 -0.55 -0.03 1.00 3573 2668 ## genderMale 0.11 0.25 -0.39 0.60 1.00 4344 2834 ## age_c -0.06 0.13 -0.32 0.20 1.00 4897 3052 ## moincome -0.26 0.13 -0.54 -0.05 1.00 2828 2345 ## moeducation 0.43 0.34 -0.18 1.12 1.00 1837 2337 ## ## Simplex Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## moincome1[1] 0.23 0.17 0.01 0.62 1.00 2586 1682 ## moincome1[2] 0.31 0.18 0.02 0.67 1.00 3204 1734 ## moincome1[3] 0.18 0.14 0.01 0.54 1.00 3737 2207 ## moincome1[4] 0.13 0.11 0.00 0.41 1.00 3962 2429 ## moincome1[5] 0.15 0.12 0.01 0.45 1.00 4476 2881 ## moeducation1[1] 0.49 0.26 0.03 0.93 1.00 2946 2231 ## moeducation1[2] 0.37 0.24 0.02 0.87 1.00 3449 2564 ## moeducation1[3] 0.14 0.17 0.00 0.64 1.00 2171 2480 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## disc 1.00 0.00 1.00 1.00 1.00 4000 4000 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 5.3.4.1 Comparing the two models WAIC(m_comb) ## ## Computed from 4000 by 235 log-likelihood matrix ## ## Estimate SE ## elpd_waic -355.5 8.5 ## p_waic 15.9 1.0 ## waic 711.0 17.0 ## ## 2 (0.9%) p_waic estimates greater than 0.4. We recommend trying loo instead. WAIC(m_comb0) ## ## Computed from 4000 by 235 log-likelihood matrix ## ## Estimate SE ## elpd_waic -356.2 7.6 ## p_waic 9.5 0.6 ## waic 712.3 15.1 5.3.4.2 Marginal effects In these sequence of plots we plot the conditional effects on how changing one variable impacts the probability of choosing one of the five items (1-5) in the frequency of using a carsharing type/company plot(conditional_effects(m_comb, categorical = T), ask=F) 5.3.5 P2P d_p2p &lt;- d4 %&gt;% select(P2P, starts_with(&#39;fa&#39;), age_c, gender, education, income) %&gt;% drop_na() d_p2p$P2P &lt;- as.ordered(d_p2p$P2P) Ordinal regression with monotonic predictors m_p2p &lt;- brm(P2P ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education), data = d_p2p, prior = priors, family = cumulative(), cores=4 ) saveRDS(m_p2p, &#39;models/m_p2p.RDS&#39;) m_p2p0 &lt;- brm(P2P ~ gender + mo(income) + age_c + mo(education), data = d_p2p, prior = priors0, family = cumulative(), cores=4 ) saveRDS(m_p2p0, &#39;models/m_p2p0.RDS&#39;) Now we can get the summary of the model summary(m_p2p) ## Family: cumulative ## Links: mu = logit; disc = identity ## Formula: P2P ~ fa_habits + fa_climate + fa_subj + fa_trust + fa_control + gender + mo(income) + age_c + mo(education) ## Data: d_p2p (Number of observations: 493) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept[1] -3.60 0.75 -5.14 -2.15 1.00 2061 2510 ## Intercept[2] -1.35 0.52 -2.27 -0.23 1.00 2529 2776 ## Intercept[3] 0.48 0.50 -0.39 1.57 1.00 2507 2658 ## Intercept[4] 1.00 0.50 0.11 2.08 1.00 2503 2704 ## fa_habits -0.14 0.10 -0.34 0.07 1.00 3303 2611 ## fa_climate 0.07 0.11 -0.14 0.28 1.00 3652 3078 ## fa_subj -0.14 0.12 -0.38 0.09 1.00 3202 2620 ## fa_trust 0.05 0.10 -0.15 0.26 1.00 3720 3264 ## fa_control 0.31 0.11 0.10 0.54 1.00 3327 2510 ## genderMale -0.10 0.21 -0.52 0.33 1.00 3587 3067 ## age_c 0.17 0.11 -0.04 0.41 1.00 3898 3010 ## moincome 0.35 0.09 0.19 0.53 1.00 3117 2355 ## moeducation 0.50 0.16 0.22 0.85 1.00 2335 2346 ## ## Simplex Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## moincome1[1] 0.10 0.08 0.00 0.30 1.00 2987 1866 ## moincome1[2] 0.14 0.09 0.01 0.35 1.00 2985 1635 ## moincome1[3] 0.15 0.11 0.01 0.41 1.00 3463 1693 ## moincome1[4] 0.34 0.17 0.04 0.68 1.00 4161 2626 ## moincome1[5] 0.27 0.16 0.02 0.61 1.00 3644 1977 ## moeducation1[1] 0.32 0.19 0.02 0.69 1.00 2430 1956 ## moeducation1[2] 0.47 0.20 0.09 0.86 1.00 3195 2519 ## moeducation1[3] 0.20 0.14 0.01 0.56 1.00 4021 2399 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## disc 1.00 0.00 1.00 1.00 1.00 4000 4000 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 5.3.5.1 Comparing the two models WAIC(m_p2p) ## ## Computed from 4000 by 493 log-likelihood matrix ## ## Estimate SE ## elpd_waic -447.0 22.2 ## p_waic 15.5 1.2 ## waic 893.9 44.4 ## ## 3 (0.6%) p_waic estimates greater than 0.4. We recommend trying loo instead. WAIC(m_p2p0) ## ## Computed from 4000 by 493 log-likelihood matrix ## ## Estimate SE ## elpd_waic -448.0 21.9 ## p_waic 10.1 0.9 ## waic 896.1 43.7 ## ## 2 (0.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. 5.3.5.2 Marginal effects In these sequence of plots we plot the conditional effects on how changing one variable impacts the probability of choosing one of the five items (1-5) in the frequency of using a carsharing type/company plot(conditional_effects(m_p2p, categorical = T), ask=F) 5.4 Figures for the paper 5.4.1 Habits panel habits_ff &lt;- plot(conditional_effects(m_ff, effects=&quot;fa_habits&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Habits&quot;, title = &quot;FF&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank()) habits_rtsba &lt;- plot(conditional_effects(m_rtsba, effects=&quot;fa_habits&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Habits&quot;, title = &quot;RTSB_A&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) habits_rtsbb &lt;- plot(conditional_effects(m_rtsbb, effects=&quot;fa_habits&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Habits&quot;, title = &quot;RTSB_B&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.y=element_blank(), axis.text.y = element_blank()) habits_comb &lt;- plot(conditional_effects(m_comb, effects=&quot;fa_habits&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Habits&quot;, title = &quot;COMB&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) habits_p2p &lt;- plot(conditional_effects(m_p2p, effects=&quot;fa_habits&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Habits&quot;, title = &quot;P2P&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.x=element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) 5.4.2 Climate panel climate_ff &lt;- plot(conditional_effects(m_ff, effects=&quot;fa_climate&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Climate&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(),) climate_rtsba &lt;- plot(conditional_effects(m_rtsba, effects=&quot;fa_climate&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Climate&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), axis.text.y = element_blank(), plot.title = element_blank(), axis.title.y=element_blank()) climate_rtsbb &lt;- plot(conditional_effects(m_rtsbb, effects=&quot;fa_climate&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Climate&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.y=element_blank(), plot.title = element_blank(), axis.text.y = element_blank()) climate_comb &lt;- plot(conditional_effects(m_comb, effects=&quot;fa_climate&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Climate&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) climate_p2p &lt;- plot(conditional_effects(m_p2p, effects=&quot;fa_climate&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Climate&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) 5.4.3 Subjective norm panel subjective_ff &lt;- plot(conditional_effects(m_ff, effects=&quot;fa_subj&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Subjective norm&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank()) subjective_rtsba &lt;- plot(conditional_effects(m_rtsba, effects=&quot;fa_subj&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Subjective norm&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), axis.text.y = element_blank(), plot.title = element_blank(), axis.title.y=element_blank()) subjective_rtsbb &lt;- plot(conditional_effects(m_rtsbb, effects=&quot;fa_subj&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Subjective norm&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.y=element_blank(), plot.title = element_blank(), axis.text.y = element_blank()) subjective_comb &lt;- plot(conditional_effects(m_comb, effects=&quot;fa_subj&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Subjective norm&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) subjective_p2p &lt;- plot(conditional_effects(m_p2p, effects=&quot;fa_subj&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Subjective norm&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) 5.4.4 Trust panel trust_ff &lt;- plot(conditional_effects(m_ff, effects=&quot;fa_trust&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Trust&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(),) trust_rtsba &lt;- plot(conditional_effects(m_rtsba, effects=&quot;fa_trust&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Trust&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), axis.text.y = element_blank(), plot.title = element_blank(), axis.title.y=element_blank()) trust_rtsbb &lt;- plot(conditional_effects(m_rtsbb, effects=&quot;fa_trust&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Trust&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.y=element_blank(), plot.title = element_blank(), axis.text.y = element_blank()) trust_comb &lt;- plot(conditional_effects(m_comb, effects=&quot;fa_trust&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Trust&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) trust_p2p &lt;- plot(conditional_effects(m_p2p, effects=&quot;fa_trust&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Trust&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) 5.4.5 Control panel control_ff &lt;- plot(conditional_effects(m_ff, effects=&quot;fa_control&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Control&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(),) control_rtsba &lt;- plot(conditional_effects(m_rtsba, effects=&quot;fa_control&quot;,categorical = T))[[1]] + coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Control&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), axis.text.y = element_blank(), plot.title = element_blank(), axis.title.y=element_blank()) control_rtsbb &lt;- plot(conditional_effects(m_rtsbb, effects=&quot;fa_control&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Control&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.y=element_blank(), plot.title = element_blank(), axis.text.y = element_blank()) control_comb &lt;- plot(conditional_effects(m_comb, effects=&quot;fa_control&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Control&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;)+ theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) control_p2p &lt;- plot(conditional_effects(m_p2p, effects=&quot;fa_control&quot;,categorical = T))[[1]]+ coord_cartesian(ylim = c(0,1)) + labs(x=&quot;Control&quot;, fill = &quot;Response&quot;, colour = &quot;Response&quot;) + theme(axis.title.x=element_blank(), plot.title = element_blank(), axis.text.y = element_blank(), axis.title.y=element_blank()) 5.4.6 Merging panels habits &lt;- (habits_ff + habits_rtsba + habits_rtsbb + habits_comb + habits_p2p ) + plot_layout(nrow=1) climate &lt;- (climate_ff + climate_rtsba + climate_rtsbb +climate_comb +climate_p2p)+ plot_layout(nrow=1) subjective &lt;- (subjective_ff + subjective_rtsba + subjective_rtsbb +subjective_comb +subjective_p2p)+ plot_layout(nrow=1) trust &lt;- (trust_ff + trust_rtsba + trust_rtsbb +trust_comb +trust_p2p)+ plot_layout(nrow=1) control &lt;- (control_ff + control_rtsba + control_rtsbb + control_comb + control_p2p ) + plot_layout(nrow=1) panel &lt;- (habits / climate/ subjective / trust /control) + plot_layout(guides = &quot;collect&quot;) &amp; theme(legend.position = &#39;bottom&#39;) panel "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
